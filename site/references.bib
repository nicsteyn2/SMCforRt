@article{abbottEstimatingTimevaryingReproduction2020,
  title = {Estimating the Time-Varying Reproduction Number of {{SARS-CoV-2}} Using National and Subnational Case Counts},
  author = {Abbott, Sam and Hellewell, Joel and Thompson, Robin N. and Sherratt, Katharine and Gibbs, Hamish P. and Bosse, Nikos I. and Munday, James D. and Meakin, Sophie and Doughty, Emma L. and Chun, June Young and Chan, Yung-Wai Desmond and Finger, Flavio and Campbell, Paul and Endo, Akira and Pearson, Carl A. B. and Gimma, Amy and Russell, Tim and {CMMID COVID modelling group} and Flasche, Stefan and Kucharski, Adam J. and Eggo, Rosalind M. and Funk, Sebastian},
  year = {2020},
  month = dec,
  journal = {Wellcome Open Research},
  volume = {5},
  pages = {112},
  issn = {2398-502X},
  doi = {10.12688/wellcomeopenres.16006.2},
  urldate = {2023-09-09},
  abstract = {Background:               Assessing temporal variations in transmission in different countries is essential for monitoring the epidemic, evaluating the effectiveness of public health interventions and estimating the impact of changes in policy.                                                      Methods:               We use case and death notification data to generate daily estimates of the time-varying reproduction number globally, regionally, nationally, and subnationally over a 12-week rolling window. Our modelling framework, based on open source tooling, accounts for uncertainty in reporting delays, so that the reproduction number is estimated based on underlying latent infections.                                                      Results:               Estimates of the reproduction number, trajectories of infections, and forecasts are displayed on a dedicated website as both maps and time series, and made available to download in tabular form.                                                      Conclusions:               ~This decision-support tool can be used to assess changes in virus transmission both globally, regionally, nationally, and subnationally. This allows public health officials and policymakers to track the progress of the outbreak in near real-time using an epidemiologically valid measure. As well as providing regular updates on our website, we also provide an open source tool-set so that our approach can be used directly by researchers and policymakers on confidential data-sets. We hope that our tool will be used to support decisions in countries worldwide throughout the ongoing COVID-19 pandemic.},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/EWIYAV4N/Abbott et al. - 2020 - Estimating the time-varying reproduction number of.pdf}
}

@misc{alvarezRemovingWeeklyAdministrative2020,
  title = {Removing Weekly Administrative Noise in the Daily Count of {{COVID-19}} New Cases. {{Application}} to the Computation of {{Rt}}},
  author = {Alvarez, Luis and Colom, Miguel and Morel, Jean-Michel},
  year = {2020},
  month = nov,
  pages = {2020.11.16.20232405},
  publisher = {medRxiv},
  doi = {10.1101/2020.11.16.20232405},
  urldate = {2024-10-27},
  abstract = {The way each country counts and reports the incident cases of SARS-CoV-2 infections is strongly affected by the ``weekend effect''. During the weekend, fewer tests are carried out and there is a delay in the registration of cases. This introduces an ``administrative noise'' that can strongly disturb the calculation of trend estimators such as the effective reproduction number R(t). In this work we propose a procedure to correct the incidence curve and obtain a better fit between the number of infected and the one expected using the renewal equation. The classic way to deal with the administrative noise is to invoke its weekly period and therefore to filter the incidence curve by a seven days sliding mean. Yet this has three drawbacks: the first one is a loss of resolution. The second one is that a 7-day mean filter hinders the estimate of the effective reproduction number R(t) in the last three days before present. The third drawback of a mean filter is that it implicitly assumes the administrative noise to be additive and time invariant. The present study supports the idea that the administrative is better dealt with as being both periodic and multiplicative. The simple method that derives from these assumptions amount to multiplying the number of infected by a correcting factor which depends on the day of the week. This correcting factor is estimated from the incidence curve itself. The validity of the method is demonstrated by its positive impact on the accuracy of an the estimates of R(t). To exemplify the advantages of the multiplicative periodic correction, we apply it to Sweden, Germany, France and Spain. We observe that the estimated administrative noise is country dependent, and that the proposed strategy manages to reduce it noise considerably. An implementation of this technique is available at www.ipol.im/ern, where it can be tested on the daily incidence curves of an extensive list of states and geographic areas provided by the European Centre for Disease Prevention and Control.},
  archiveprefix = {medRxiv},
  copyright = {{\copyright} 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/U7AEUWQW/Alvarez et al. - 2020 - Removing weekly administrative noise in the daily .pdf}
}

@article{andrieuParticleMarkovChain2010,
  title = {Particle {{Markov}} Chain {{Monte Carlo}} Methods},
  author = {Andrieu, Christophe and Doucet, Arnaud and Holenstein, Roman},
  year = {2010},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume = {72},
  number = {3},
  pages = {269--342},
  issn = {1467-9868},
  doi = {10.1111/j.1467-9868.2009.00736.x},
  urldate = {2023-09-13},
  abstract = {Summary. Markov chain Monte Carlo and sequential Monte Carlo methods have emerged as the two main tools to sample from high dimensional probability distributions. Although asymptotic convergence of Markov chain Monte Carlo algorithms is ensured under weak assumptions, the performance of these algorithms is unreliable when the proposal distributions that are used to explore the space are poorly chosen and/or if highly correlated variables are updated independently. We show here how it is possible to build efficient high dimensional proposal distributions by using sequential Monte Carlo methods. This allows us not only to improve over standard Markov chain Monte Carlo schemes but also to make Bayesian inference feasible for a large class of statistical models where this was not previously so. We demonstrate these algorithms on a non-linear state space model and a L{\'e}vy-driven stochastic volatility model.},
  copyright = {{\copyright} 2010 Royal Statistical Society},
  langid = {english},
  keywords = {Bayesian inference,Markov chain Monte Carlo methods,Sequential Monte Carlo methods,State space models},
  file = {/Users/nicsteyn/Documents/Zotero/storage/GV9SE5EL/Andrieu et al. - 2010 - Particle Markov chain Monte Carlo methods.pdf;/Users/nicsteyn/Documents/Zotero/storage/PFH47MWT/j.1467-9868.2009.00736.html}
}

@article{andrieuTutorialAdaptiveMCMC2008,
  title = {A Tutorial on Adaptive {{MCMC}}},
  author = {Andrieu, Christophe and Thoms, Johannes},
  year = {2008},
  month = dec,
  journal = {Statistics and Computing},
  volume = {18},
  number = {4},
  pages = {343--373},
  issn = {1573-1375},
  doi = {10.1007/s11222-008-9110-y},
  urldate = {2024-10-25},
  abstract = {We review adaptive Markov chain Monte Carlo algorithms (MCMC) as a mean to optimise their performance. Using simple toy examples we review their theoretical underpinnings, and in particular show why adaptive MCMC algorithms might fail when some fundamental properties are not satisfied. This leads to guidelines concerning the design of correct algorithms. We then review criteria and the useful framework of stochastic approximation, which allows one to systematically optimise generally used criteria, but also analyse the properties of adaptive MCMC algorithms. We then propose a series of novel adaptive algorithms which prove to be robust and reliable in practice. These algorithms are applied to artificial and high dimensional scenarios, but also to the classic mine disaster dataset inference problem.},
  langid = {english},
  keywords = {Adaptive MCMC,Artificial Intelligence,Controlled Markov chain,MCMC,Stochastic approximation},
  file = {/Users/nicsteyn/Documents/Zotero/storage/T3XH2FKJ/Andrieu and Thoms - 2008 - A tutorial on adaptive MCMC.pdf}
}

@misc{ariasBayesianEstimationEpidemiological2021,
  type = {{{SSRN Scholarly Paper}}},
  title = {Bayesian {{Estimation}} of {{Epidemiological Models}}: {{Methods}}, {{Causality}}, and {{Policy Trade-Offs}}},
  shorttitle = {Bayesian {{Estimation}} of {{Epidemiological Models}}},
  author = {Arias, Jonas and {Fern{\'a}ndez-Villaverde}, Jes{\'u}s and {Rubio-Ram{\'i}rez}, Juan F. and Shin, Minchul},
  year = {2021},
  month = may,
  number = {3843822},
  address = {Rochester, NY},
  doi = {10.21799/frbp.wp.2021.18},
  urldate = {2024-10-03},
  abstract = {We present a general framework for Bayesian estimation and causality assessment in epidemiological models. The key to our approach is the use of sequential Monte Carlo methods to evaluate the likelihood of a generic epidemiological model. Once we have the likelihood, we specify priors and rely on a Markov chain Monte Carlo to sample from the posterior distribution. We show how to use the posterior simulation outputs as inputs for exercises in causality assessment. We apply our approach to Belgian data for the COVID-19 epidemic during 2020. Our estimated time-varying-parameters SIRD model captures the data dynamics very well, including the three waves of infections. We use the estimated (true) number of new cases and the time-varying effective reproduction number from the epidemiological model as information for structural vector autoregressions and local projections. We document how additional government-mandated mobility curtailments would have reduced deaths at zero cost or a very small cost in terms of output.},
  langid = {english},
  keywords = {Bayesian estimation,Causality,Epidemiological models,policy interventions},
  file = {/Users/nicsteyn/Documents/Zotero/storage/68BXZH5N/Arias et al. - 2021 - Bayesian Estimation of Epidemiological Models Met.pdf}
}

@article{azmonEstimationReproductionNumber2014,
  title = {On the Estimation of the Reproduction Number Based on Misreported Epidemic Data},
  author = {Azmon, Amin and Faes, Christel and Hens, Niel},
  year = {2014},
  journal = {Statistics in Medicine},
  volume = {33},
  number = {7},
  pages = {1176--1192},
  issn = {1097-0258},
  doi = {10.1002/sim.6015},
  urldate = {2024-09-05},
  abstract = {AbstractEpidemic data often suffer from underreporting and delay in reporting. In this paper, we investigated the impact of delays and underreporting on estimates of reproduction number. We used a thinned version of the epidemic renewal equation to describe the epidemic process while accounting for the underlying reporting system. Assuming a constant reporting parameter, we used different delay patterns to represent the delay structure in our model. Instead of assuming a fixed delay distribution, we estimated the delay parameters while assuming a smooth function for the reproduction number over time. In order to estimate the parameters, we used a Bayesian semiparametric approach with penalized splines, allowing both flexibility and exact inference provided by MCMC. To show the performance of our method, we performed different simulation studies. We conducted sensitivity analyses to investigate the impact of misspecification of the delay pattern and the impact of assuming nonconstant reporting parameters on the estimates of the reproduction numbers. We showed that, whenever available, additional information about time-dependent underreporting can be taken into account. As an application of our method, we analyzed confirmed daily A(H1N1) v2009 cases made publicly available by the World Health Organization for Mexico and the USA. Copyright {\copyright} 2013 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {composite link model,delay in reporting,epidemic renewal equation,MCMC,underreporting},
  file = {/Users/nicsteyn/Documents/Zotero/storage/JZGCRLGK/sim.html}
}

@misc{banholzerComparisonShorttermProbabilistic2023,
  title = {A Comparison of Short-Term Probabilistic Forecasts for the Incidence of {{COVID-19}} Using Mechanistic and Statistical Time Series Models},
  author = {Banholzer, Nicolas and Mellan, Thomas and Unwin, H. Juliette T. and Feuerriegel, Stefan and Mishra, Swapnil and Bhatt, Samir},
  year = {2023},
  month = may,
  number = {arXiv:2305.00933},
  eprint = {2305.00933},
  primaryclass = {cs, q-bio, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.00933},
  urldate = {2024-09-15},
  abstract = {Short-term forecasts of infectious disease spread are a critical component in risk evaluation and public health decision making. While different models for short-term forecasting have been developed, open questions about their relative performance remain. Here, we compare short-term probabilistic forecasts of popular mechanistic models based on the renewal equation with forecasts of statistical time series models. Our empirical comparison is based on data of the daily incidence of COVID-19 across six large US states over the first pandemic year. We find that, on average, probabilistic forecasts from statistical time series models are overall at least as accurate as forecasts from mechanistic models. Moreover, statistical time series models better capture volatility. Our findings suggest that domain knowledge, which is integrated into mechanistic models by making assumptions about disease dynamics, does not improve short-term forecasts of disease incidence. We note, however, that forecasting is often only one of many objectives and thus mechanistic models remain important, for example, to model the impact of vaccines or the emergence of new variants.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Quantitative Biology - Populations and Evolution,Statistics - Applications,Statistics - Machine Learning},
  file = {/Users/nicsteyn/Documents/Zotero/storage/L9ATPLB7/Banholzer et al. - 2023 - A comparison of short-term probabilistic forecasts.pdf;/Users/nicsteyn/Documents/Zotero/storage/ZHZMEC6W/2305.html}
}

@article{bhatiaExtendingEpiEstimEstimate2023,
  title = {Extending {{EpiEstim}} to Estimate the Transmission Advantage of Pathogen Variants in Real-Time: {{SARS-CoV-2}} as a Case-Study},
  shorttitle = {Extending {{EpiEstim}} to Estimate the Transmission Advantage of Pathogen Variants in Real-Time},
  author = {Bhatia, Sangeeta and Wardle, Jack and Nash, Rebecca K. and Nouvellet, Pierre and Cori, Anne},
  year = {2023},
  month = sep,
  journal = {Epidemics},
  volume = {44},
  pages = {100692},
  issn = {1755-4365},
  doi = {10.1016/j.epidem.2023.100692},
  urldate = {2024-09-15},
  abstract = {The evolution of SARS-CoV-2 has demonstrated that emerging variants can set back the global COVID-19 response. The ability to rapidly assess the threat of new variants is critical for timely optimisation of control strategies. We present a novel method to estimate the effective transmission advantage of a new variant compared to a reference variant combining information across multiple locations and over time. Through an extensive simulation study designed to mimic real-time epidemic contexts, we show that our method performs well across a range of scenarios and provide guidance on its optimal use and interpretation of results. We also provide an open-source software implementation of our method. The computational speed of our tool enables users to rapidly explore spatial and temporal variations in the estimated transmission advantage. We estimate that the SARS-CoV-2 Alpha variant is 1.46 (95\% Credible Interval 1.44--1.47) and 1.29 (95\% CrI 1.29--1.30) times more transmissible than the wild type, using data from England and France respectively. We further estimate that Delta is 1.77 (95\% CrI 1.69--1.85) times more transmissible than Alpha (England data). Our approach can be used as an important first step towards quantifying the threat of emerging or co-circulating variants of infectious pathogens in real-time.},
  keywords = {Disease transmission,Infectious disease epidemiology,Mathematical modelling,Parameter inference,Sars-Cov-2},
  file = {/Users/nicsteyn/Documents/Zotero/storage/WSI3XM7V/Bhatia et al. - 2023 - Extending EpiEstim to estimate the transmission ad.pdf;/Users/nicsteyn/Documents/Zotero/storage/6RRZCE8L/S1755436523000282.html}
}

@article{bhattSemimechanisticBayesianModelling2023,
  title = {Semi-Mechanistic {{Bayesian}} Modelling of {{COVID-19}} with Renewal Processes},
  author = {Bhatt, Samir and Ferguson, Neil and Flaxman, Seth and Gandy, Axel and Mishra, Swapnil and Scott, James A},
  year = {2023},
  month = oct,
  journal = {Journal of the Royal Statistical Society Series A: Statistics in Society},
  volume = {186},
  number = {4},
  pages = {601--615},
  issn = {0964-1998},
  doi = {10.1093/jrsssa/qnad030},
  urldate = {2024-10-27},
  abstract = {We propose a general Bayesian approach to modelling epidemics such as COVID-19. The approach grew out of specific analyses conducted during the pandemic, in particular, an analysis concerning the effects of non-pharmaceutical interventions (NPIs) in reducing COVID-19 transmission in 11 European countries. The model parameterises the time-varying reproduction number Rt through a multilevel regression framework in which covariates can be governmental interventions, changes in mobility patterns, or other behavioural measures. Bayesian multilevel modelling allows a joint fit across regions, with partial pooling to share strength. This innovation was critical to our timely estimates of the impact of lockdown and other NPIs in the European epidemics: estimates from countries at later stages in their epidemics informed those of countries at earlier stages. Originally released as Imperial College Reports, the validity of this approach was borne out by the subsequent course of the epidemic. Our framework provides a fully generative model for latent infections and derived observations, including deaths, cases, hospitalizations, ICU admissions, and seroprevalence surveys. In this article, we additionally explore the confounded nature of NPIs and mobility. Versions of our model were used by New York State, Tennessee, and Scotland to estimate the current epidemic situation and make policy decisions.},
  file = {/Users/nicsteyn/Documents/Zotero/storage/USGVS5HL/Bhatt et al. - 2023 - Semi-mechanistic Bayesian modelling of COVID-19 wi.pdf}
}

@article{bracherPreregisteredShorttermForecasting2021,
  title = {A Pre-Registered Short-Term Forecasting Study of {{COVID-19}} in {{Germany}} and {{Poland}} during the Second Wave},
  author = {Bracher, J. and Wolffram, D. and Deuschel, J. and G{\"o}rgen, K. and Ketterer, J. L. and Ullrich, A. and Abbott, S. and Barbarossa, M. V. and Bertsimas, D. and Bhatia, S. and Bodych, M. and Bosse, N. I. and Burgard, J. P. and Castro, L. and Fairchild, G. and Fuhrmann, J. and Funk, S. and Gogolewski, K. and Gu, Q. and Heyder, S. and Hotz, T. and Kheifetz, Y. and Kirsten, H. and Krueger, T. and Krymova, E. and Li, M. L. and Meinke, J. H. and Michaud, I. J. and Niedzielewski, K. and O{\.z}a{\'n}ski, T. and Rakowski, F. and Scholz, M. and Soni, S. and Srivastava, A. and Zieli{\'n}ski, J. and Zou, D. and Gneiting, T. and Schienle, M.},
  year = {2021},
  month = aug,
  journal = {Nature Communications},
  volume = {12},
  number = {1},
  pages = {5173},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-021-25207-0},
  urldate = {2025-02-24},
  abstract = {Disease modelling has had considerable policy impact during the ongoing COVID-19 pandemic, and it is increasingly acknowledged that combining multiple models can improve the reliability of outputs. Here we report insights from ten weeks of collaborative short-term forecasting of COVID-19 in Germany and Poland (12 October--19 December 2020). The study period covers the onset of the second wave in both countries, with tightening non-pharmaceutical interventions (NPIs) and subsequently a decay (Poland) or plateau and renewed increase (Germany) in reported cases. Thirteen independent teams provided probabilistic real-time forecasts of COVID-19 cases and deaths. These were reported for lead times of one to four weeks, with evaluation focused on one- and two-week horizons, which are less affected by changing NPIs. Heterogeneity between forecasts was considerable both in terms of point predictions and forecast spread. Ensemble forecasts showed good relative performance, in particular in terms of coverage, but did not clearly dominate single-model predictions. The study was preregistered and will be followed up in future phases of the pandemic.},
  copyright = {2021 The Author(s)},
  langid = {english},
  keywords = {Computational models,Epidemiology,SARS-CoV-2,Statistics},
  file = {/Users/nicsteyn/Documents/Zotero/storage/6VS2S8HL/Bracher et al. - 2021 - A pre-registered short-term forecasting study of C.pdf}
}

@article{calvettiBayesianParticleFilter2021,
  title = {Bayesian Particle Filter Algorithm for Learning Epidemic Dynamics},
  author = {Calvetti, D. and Hoover, A. and Rose, J. and Somersalo, E.},
  year = {2021},
  month = oct,
  journal = {Inverse Problems},
  volume = {37},
  number = {11},
  pages = {115008},
  publisher = {IOP Publishing},
  issn = {0266-5611},
  doi = {10.1088/1361-6420/ac2cdc},
  urldate = {2024-09-02},
  abstract = {In this article, we consider a dynamic model for the spread of epidemics, in particular of COVID-19, and the inverse problem of estimating sequentially the time evolution of the unknown state and the model parameters based on noisy observations of the new daily infections. A characteristic of COVID-19 is the significant proportion of secondary infections though contacts with asymptomatic or oligosymptomatic infectious individuals. Since most of these individuals are not accounted for in the number of new daily infections, the size of this cohort can be inferred only indirectly through the underlying model. The evolution model used to propagate the current state from one data instance to the next is a suitably modified SEIR compartment model, providing the expected value for the new daily infection count that is modeled as a Poisson distributed random variable. The estimation of the state and the model parameters is based on a Bayesian particle filtering algorithm. The sequential Bayesian framework naturally provides a quantification of the uncertainty in the estimates of the model parameters, basic reproduction number, and size of the cohorts. Of particular interest is the fact that the algorithm makes it possible to estimate the size of the asymptomatic cohort, a key component for understanding the COVID-19 dynamics, and for planning mitigation measures. Alternative versions of the classical basic reproduction number for estimating the speed of the propagation of the disease are also proposed. The viability of the algorithm is demonstrated through a set of computed examples with both simulated realistic data and actual real data from selected US counties. The numerical tests show that the algorithm reproduces a ratio of asymptomatic vs symptomatic cohort sizes remarkably close to what is currently suggested by the Center for Disease Control.},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/7ERPFMN7/Calvetti et al. - 2021 - Bayesian particle filter algorithm for learning ep.pdf}
}

@book{chopinIntroductionSequentialMonte2020,
  title = {An {{Introduction}} to {{Sequential Monte Carlo}}},
  author = {Chopin, Nicolas and Papaspiliopoulos, Omiros},
  year = {2020},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-47845-2},
  urldate = {2024-08-01},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-3-030-47844-5 978-3-030-47845-2},
  langid = {english},
  keywords = {Bayesian inference,data-driven science modeling and theory building,Feynman-Kac models,Hidden Markov models,Markov chain Monte Carlo,Particle filter,Sequential learning,Sequential Monte Carlo,State-space models},
  file = {/Users/nicsteyn/Documents/Zotero/storage/M5EJZDS5/Chopin and Papaspiliopoulos - 2020 - An Introduction to Sequential Monte Carlo.pdf}
}

@article{churcherMeasuringPathMalaria2014,
  title = {Measuring the Path toward Malaria Elimination},
  author = {Churcher, Thomas S. and Cohen, Justin M. and Novotny, Joseph and Ntshalintshali, Nyasatu and Kunene, Simon and Cauchemez, Simon},
  year = {2014},
  month = jun,
  journal = {Science},
  volume = {344},
  number = {6189},
  pages = {1230--1232},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1251449},
  urldate = {2025-03-10},
  file = {/Users/nicsteyn/Documents/Zotero/storage/TCDEJ35G/Churcher et al. - 2014 - Measuring the path toward malaria elimination.pdf}
}

@article{coriInferenceEpidemicDynamics2024,
  title = {Inference of Epidemic Dynamics in the {{COVID-19}} Era and Beyond},
  author = {Cori, Anne and Kucharski, Adam},
  year = {2024},
  month = sep,
  journal = {Epidemics},
  volume = {48},
  pages = {100784},
  issn = {1755-4365},
  doi = {10.1016/j.epidem.2024.100784},
  urldate = {2024-09-02},
  abstract = {The COVID-19 pandemic demonstrated the key role that epidemiology and modelling play in analysing infectious threats and supporting decision making in real-time. Motivated by the unprecedented volume and breadth of data generated during the pandemic, we review modern opportunities for analysis to address questions that emerge during a major modern epidemic. Following the broad chronology of insights required --- from understanding initial dynamics to retrospective evaluation of interventions, we describe the theoretical foundations of each approach and the underlying intuition. Through a series of case studies, we illustrate real life applications, and discuss implications for future work.},
  keywords = {Analytics,Epidemics,infectious diseases,Inference,Modelling},
  file = {/Users/nicsteyn/Documents/Zotero/storage/FR6MK4S5/S1755436524000458.html}
}

@article{coriNewFrameworkSoftware2013,
  title = {A {{New Framework}} and {{Software}} to {{Estimate Time-Varying Reproduction Numbers During Epidemics}}},
  author = {Cori, Anne and Ferguson, Neil M. and Fraser, Christophe and Cauchemez, Simon},
  year = {2013},
  month = nov,
  journal = {American Journal of Epidemiology},
  volume = {178},
  number = {9},
  pages = {1505--1512},
  issn = {0002-9262},
  doi = {10.1093/aje/kwt133},
  urldate = {2023-09-09},
  abstract = {The quantification of transmissibility during epidemics is essential to designing and adjusting public health responses. Transmissibility can be measured by the reproduction number R, the average number of secondary cases caused by an infected individual. Several methods have been proposed to estimate R over the course of an epidemic; however, they are usually difficult to implement for people without a strong background in statistical modeling. Here, we present a ready-to-use tool for estimating R from incidence time series, which is implemented in popular software including Microsoft Excel (Microsoft Corporation, Redmond, Washington). This tool produces novel, statistically robust analytical estimates of R and incorporates uncertainty in the distribution of the serial interval (the time between the onset of symptoms in a primary case and the onset of symptoms in secondary cases). We applied the method to 5 historical outbreaks; the resulting estimates of R are consistent with those presented in the literature. This tool should help epidemiologists quantify temporal changes in the transmission intensity of future epidemics by using surveillance data.},
  file = {/Users/nicsteyn/Documents/Zotero/storage/NPPTIWW6/Cori et al. - 2013 - A New Framework and Software to Estimate Time-Vary.pdf;/Users/nicsteyn/Documents/Zotero/storage/2PWR7ARB/89262.html}
}

@article{crealSurveySequentialMonte2012,
  title = {A {{Survey}} of {{Sequential Monte Carlo Methods}} for {{Economics}} and {{Finance}}},
  author = {Creal, Drew},
  year = {2012},
  month = may,
  journal = {Econometric Reviews},
  volume = {31},
  number = {3},
  pages = {245--296},
  publisher = {Taylor \& Francis},
  issn = {0747-4938},
  doi = {10.1080/07474938.2011.607333},
  urldate = {2024-10-29},
  abstract = {This article serves as an introduction and survey for economists to the field of sequential Monte Carlo methods which are also known as particle filters. Sequential Monte Carlo methods are simulation-based algorithms used to compute the high-dimensional and/or complex integrals that arise regularly in applied work. These methods are becoming increasingly popular in economics and finance; from dynamic stochastic general equilibrium models in macro-economics to option pricing. The objective of this article is to explain the basics of the methodology, provide references to the literature, and cover some of the theoretical results that justify the methods in practice.},
  keywords = {C11,C15,C32,Kalman filter,Markov chain Monte Carlo,Particle filter,Sequential Monte Carlo,State space models},
  file = {/Users/nicsteyn/Documents/Zotero/storage/ZEGN2PH3/Creal - 2012 - A Survey of Sequential Monte Carlo Methods for Eco.pdf}
}

@article{creswellBayesianNonparametricMethod2023,
  title = {A {{Bayesian}} Nonparametric Method for Detecting Rapid Changes in Disease Transmission},
  author = {Creswell, Richard and Robinson, Martin and Gavaghan, David and Parag, Kris V. and Lei, Chon Lok and Lambert, Ben},
  year = {2023},
  month = feb,
  journal = {Journal of Theoretical Biology},
  volume = {558},
  pages = {111351},
  issn = {0022-5193},
  doi = {10.1016/j.jtbi.2022.111351},
  urldate = {2024-04-17},
  abstract = {Whether an outbreak of infectious disease is likely to grow or dissipate is determined through the time-varying reproduction number, Rt. Real-time or retrospective identification of changes in Rt following the imposition or relaxation of interventions can thus contribute important evidence about disease transmission dynamics which can inform policymaking. Here, we present a method for estimating shifts in Rt within a renewal model framework. Our method, which we call EpiCluster, is a Bayesian nonparametric model based on the Pitman--Yor process. We assume that Rt is piecewise-constant, and the incidence data and priors determine when or whether Rt should change and how many times it should do so throughout the series. We also introduce a prior which induces sparsity over the number of changepoints. Being Bayesian, our approach yields a measure of uncertainty in Rt and its changepoints. EpiCluster is fast, straightforward to use, and we demonstrate that it provides automated detection of rapid changes in transmission, either in real-time or retrospectively, for synthetic data series where the Rt profile is known. We illustrate the practical utility of our method by fitting it to case data of outbreaks of COVID-19 in Australia and Hong Kong, where it finds changepoints coinciding with the imposition of non-pharmaceutical interventions. Bayesian nonparametric methods, such as ours, allow the volume and complexity of the data to dictate the number of parameters required to approximate the process and should find wide application in epidemiology. This manuscript was submitted as part of a theme issue on ``Modelling COVID-19 and Preparedness for Future Pandemics''.},
  keywords = {Bayesian nonparametrics,Changepoint detection,COVID-19,Epidemiology,Outbreaks,Reproduction number},
  file = {/Users/nicsteyn/Documents/Zotero/storage/AZ3RXRT9/Creswell et al. - 2023 - A Bayesian nonparametric method for detecting rapi.pdf;/Users/nicsteyn/Documents/Zotero/storage/II5XHLPP/S0022519322003423.html}
}

@article{daiInvitationSequentialMonte2022,
  title = {An {{Invitation}} to {{Sequential Monte Carlo Samplers}}},
  author = {Dai, Chenguang and Heng, Jeremy and Jacob, Pierre E. and Whiteley, Nick},
  year = {2022},
  month = jul,
  journal = {Journal of the American Statistical Association},
  volume = {117},
  number = {539},
  pages = {1587--1600},
  issn = {0162-1459, 1537-274X},
  doi = {10.1080/01621459.2022.2087659},
  urldate = {2024-10-03},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/G45QMLI6/Dai et al. - 2022 - An Invitation to Sequential Monte Carlo Samplers.pdf}
}

@article{deangelisFourKeyChallenges2015,
  title = {Four Key Challenges in Infectious Disease Modelling Using Data from Multiple Sources},
  author = {De Angelis, Daniela and Presanis, Anne M. and Birrell, Paul J. and Tomba, Gianpaolo Scalia and House, Thomas},
  year = {2015},
  month = mar,
  journal = {Epidemics},
  series = {Challenges in {{Modelling Infectious DIsease Dynamics}}},
  volume = {10},
  pages = {83--87},
  issn = {1755-4365},
  doi = {10.1016/j.epidem.2014.09.004},
  urldate = {2025-03-15},
  abstract = {Public health-related decision-making on policies aimed at controlling epidemics is increasingly evidence-based, exploiting multiple sources of data. Policy makers rely on complex models that are required to be robust, realistically approximating epidemics and consistent with all relevant data. Meeting these requirements in a statistically rigorous and defendable manner poses a number of challenging problems. How to weight evidence from different datasets and handle dependence between them, efficiently estimate and critically assess complex models are key challenges that we expound in this paper, using examples from influenza modelling.},
  keywords = {Bayesian,Complex models,Epidemics,Evidence synthesis,Multiple sources,Statistical inference},
  file = {/Users/nicsteyn/Documents/Zotero/storage/N9N87XIL/De Angelis et al. - 2015 - Four key challenges in infectious disease modellin.pdf;/Users/nicsteyn/Documents/Zotero/storage/MJD7IS5V/S175543651400053X.html}
}

@article{desimoneBayesianApproachMonitoring2020,
  title = {A {{Bayesian}} Approach for Monitoring Epidemics in Presence of Undetected Cases},
  author = {De Simone, Andrea and Piangerelli, Marco},
  year = {2020},
  month = nov,
  journal = {Chaos, Solitons \& Fractals},
  volume = {140},
  pages = {110167},
  issn = {0960-0779},
  doi = {10.1016/j.chaos.2020.110167},
  urldate = {2024-10-27},
  abstract = {One of the key indicators used in tracking the evolution of an infectious disease is the reproduction number. This quantity is usually computed using the reported number of cases, but ignoring that many more individuals may be infected (e.g. asymptomatic carriers). We develop a Bayesian procedure to quantify the impact of undetected infectious cases on the determination of the effective reproduction number. Our approach is stochastic, data-driven and not relying on any compartmental model. It is applied to the COVID-19 outbreak in eight different countries and all Italian regions, showing that the effect of undetected cases leads to estimates of the effective reproduction numbers larger than those obtained only with the reported cases by factors ranging from two to ten.},
  keywords = {Bayesian inference,Computational epidemiology,COVID-19,Stochastic process},
  file = {/Users/nicsteyn/Documents/Zotero/storage/ALKHDHPV/De Simone and Piangerelli - 2020 - A Bayesian approach for monitoring epidemics in pr.pdf;/Users/nicsteyn/Documents/Zotero/storage/IWI2UIEU/S0960077920305634.html}
}

@article{djaafaraQuantitativeFrameworkDefining2021,
  title = {A {{Quantitative Framework}} for {{Defining}} the {{End}} of an {{Infectious Disease Outbreak}}: {{Application}} to {{Ebola Virus Disease}}},
  shorttitle = {A {{Quantitative Framework}} for {{Defining}} the {{End}} of an {{Infectious Disease Outbreak}}},
  author = {Djaafara, Bimandra A and Imai, Natsuko and Hamblion, Esther and Impouma, Benido and Donnelly, Christl A and Cori, Anne},
  year = {2021},
  month = apr,
  journal = {American Journal of Epidemiology},
  volume = {190},
  number = {4},
  pages = {642--651},
  issn = {0002-9262},
  doi = {10.1093/aje/kwaa212},
  urldate = {2025-01-30},
  abstract = {The end-of-outbreak declaration is an important step in controlling infectious disease outbreaks. Objective estimation of the confidence level that an outbreak is over is important to reduce the risk of postdeclaration flare-ups. We developed a simulation-based model with which to quantify that confidence and tested it on simulated Ebola virus disease data. We found that these confidence estimates were most sensitive to the instantaneous reproduction number, the reporting rate, and the time between the symptom onset and death or recovery of the last detected case. For Ebola virus disease, our results suggested that the current World Health Organization criterion of 42 days since the recovery or death of the last detected case is too short and too sensitive to underreporting. Therefore, we suggest a shift to a preliminary end-of-outbreak declaration after 63 days from the symptom onset day of the last detected case. This preliminary declaration should still be followed by 90 days of enhanced surveillance to capture potential flare-ups of cases, after which the official end of the outbreak can be declared. This sequence corresponds to more than 95\% confidence that an outbreak is over in most of the scenarios examined. Our framework is generic and therefore could be adapted to estimate end-of-outbreak confidence for other infectious diseases.},
  file = {/Users/nicsteyn/Documents/Zotero/storage/75UP8NF6/Djaafara et al. - 2021 - A Quantitative Framework for Defining the End of a.pdf;/Users/nicsteyn/Documents/Zotero/storage/2NQ9N66J/5922782.html}
}

@article{doucetEfficientImplementationMarkov2015,
  title = {Efficient Implementation of {{Markov}} Chain {{Monte Carlo}} When Using an Unbiased Likelihood Estimator},
  author = {Doucet, A. and Pitt, M. K. and Deligiannidis, G. and Kohn, R.},
  year = {2015},
  month = jun,
  journal = {Biometrika},
  volume = {102},
  number = {2},
  pages = {295--313},
  issn = {0006-3444},
  doi = {10.1093/biomet/asu075},
  urldate = {2024-10-25},
  abstract = {When an unbiased estimator of the likelihood is used within a Metropolis--Hastings chain, it is necessary to trade off the number of Monte Carlo samples used to construct this estimator against the asymptotic variances of the averages computed under this chain. Using many Monte Carlo samples will typically result in Metropolis--Hastings averages with lower asymptotic variances than the corresponding averages that use fewer samples; however, the computing time required to construct the likelihood estimator increases with the number of samples. Under the assumption that the distribution of the additive noise introduced by the loglikelihood estimator is Gaussian with variance inversely proportional to the number of samples and independent of the parameter value at which it is evaluated, we provide guidelines on the number of samples to select. We illustrate our results by considering a stochastic volatility model applied to stock index returns.},
  file = {/Users/nicsteyn/Documents/Zotero/storage/GM6IIB3C/Doucet et al. - 2015 - Efficient implementation of Markov chain Monte Car.pdf;/Users/nicsteyn/Documents/Zotero/storage/BA2H5425/246727.html}
}

@book{doucetSequentialMonteCarlo2001,
  title = {Sequential {{Monte Carlo}} Methods in Practice},
  editor = {Doucet, Arnaud and De Freitas, Nando and Gordon, Neil},
  year = {2001},
  series = {Statistics for Engineering and Information Science},
  publisher = {Springer},
  address = {New York},
  isbn = {978-0-387-95146-1},
  lccn = {QA298 .S47 2001},
  keywords = {Monte Carlo method}
}

@incollection{doucetTutorialParticleFiltering2011,
  title = {A Tutorial on Particle Filtering and Smoothing : Fiteen Years Later},
  shorttitle = {A Tutorial on Particle Filtering and Smoothing},
  author = {Doucet, Arnaud and Johansen, Adam M.},
  editor = {Crisan, Dan and Rozovskii, Boris},
  year = {2011},
  pages = {656--705},
  publisher = {Oxford University Press},
  address = {Oxford ; N.Y.},
  urldate = {2025-03-15},
  isbn = {978-0-19-953290-2},
  langid = {british},
  file = {/Users/nicsteyn/Documents/Zotero/storage/LTJ8XJ9M/37961.html}
}

@article{eilertsonEstimationPredictionMechanistic2019,
  title = {Estimation and Prediction for a Mechanistic Model of Measles Transmission Using Particle Filtering and Maximum Likelihood Estimation},
  author = {Eilertson, Kirsten E. and Fricks, John and Ferrari, Matthew J.},
  year = {2019},
  journal = {Statistics in Medicine},
  volume = {38},
  number = {21},
  pages = {4146--4158},
  issn = {1097-0258},
  doi = {10.1002/sim.8290},
  urldate = {2024-09-02},
  abstract = {Disease incidence reported directly within health systems frequently reflects a partial observation relative to the true incidence in the population. State-space models present a general framework for inferring both the dynamics of infectious disease processes and the unobserved burden of disease in the population. Here, we present a state-space model of measles transmission and vaccine-based interventions at the country-level and a particle filter-based estimation procedure. Our dynamic transmission model builds on previous work by incorporating population age-structure to allow explicit representation of age-targeted vaccine interventions. We illustrate the performance of estimators of model parameters and predictions of unobserved states on simulated data from two dynamic models: one on the annual time-scale of observations and one on the biweekly time-scale of the epidemiological dynamics. We show that our model results in approximately unbiased estimates of unobserved burden and the underreporting rate. We further illustrate the performance of the fitted model for prediction of future disease burden in the next one to 15 years.},
  langid = {english},
  keywords = {measles,particle filter,stochastic model,time series,under-reporting},
  file = {/Users/nicsteyn/Documents/Zotero/storage/82TEDW86/Eilertson et al. - 2019 - Estimation and prediction for a mechanistic model .pdf;/Users/nicsteyn/Documents/Zotero/storage/5IHPDXUF/sim.html}
}

@article{endoIntroductionParticleMarkovchain2019,
  title = {Introduction to Particle {{Markov-chain Monte Carlo}} for Disease Dynamics Modellers},
  author = {Endo, Akira and {van Leeuwen}, Edwin and Baguelin, Marc},
  year = {2019},
  month = dec,
  journal = {Epidemics},
  volume = {29},
  pages = {100363},
  issn = {1755-4365},
  doi = {10.1016/j.epidem.2019.100363},
  urldate = {2023-09-10},
  abstract = {The particle Markov-chain Monte Carlo (PMCMC) method is a powerful tool to efficiently explore high-dimensional parameter space using time-series data. We illustrate an overall picture of PMCMC with minimal but sufficient theoretical background to support the readers in the field of biomedical/health science to apply PMCMC to their studies. Some working examples of PMCMC applied to infectious disease dynamic models are presented with R code.},
  keywords = {Hidden Markov process,notion,Particle filter,Particle Markov-chain Monte Carlo,Sequential Monte Carlo,State-space models},
  file = {/Users/nicsteyn/Documents/Zotero/storage/DJ4BCVAU/Endo et al. - 2019 - Introduction to particle Markov-chain Monte Carlo .pdf;/Users/nicsteyn/Documents/Zotero/storage/4DWRG9TW/S1755436519300301.html}
}

@book{evensenDataAssimilationFundamentals2022,
  title = {Data {{Assimilation Fundamentals}}: {{A Unified Formulation}} of the {{State}} and {{Parameter Estimation Problem}}},
  shorttitle = {Data {{Assimilation Fundamentals}}},
  author = {Evensen, Geir and Vossepoel, Femke C. and Van Leeuwen, Peter Jan},
  year = {2022},
  series = {Springer {{Textbooks}} in {{Earth Sciences}}, {{Geography}} and {{Environment}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-96709-3},
  urldate = {2024-10-29},
  copyright = {https://creativecommons.org/licenses/by/4.0},
  isbn = {978-3-030-96708-6 978-3-030-96709-3},
  langid = {english},
  keywords = {4DVar,Data Assimilation,Ensemble Kalman Filter,Ensemble Methods,Open Access,Parameter Estimation,Particle Filter,Particle Flow,Representer Method},
  file = {/Users/nicsteyn/Documents/Zotero/storage/3E36STIQ/Evensen et al. - 2022 - Data Assimilation Fundamentals A Unified Formulat.pdf}
}

@misc{fadikarImprovedUncertaintyQuantification2024a,
  title = {Towards {{Improved Uncertainty Quantification}} of {{Stochastic Epidemic Models Using Sequential Monte Carlo}}},
  author = {Fadikar, Arindam and Stevens, Abby and Collier, Nicholson and Toh, Kok Ben and Morozova, Olga and Hotton, Anna and Clark, Jared and Higdon, David and Ozik, Jonathan},
  year = {2024},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2402.15619},
  urldate = {2024-10-03},
  abstract = {Sequential Monte Carlo (SMC) algorithms represent a suite of robust computational methodologies utilized for state estimation and parameter inference within dynamical systems, particularly in real-time or online environments where data arrives sequentially over time. In this research endeavor, we propose an integrated framework that combines a stochastic epidemic simulator with a sequential importance sampling (SIS) scheme to dynamically infer model parameters, which evolve due to social as well as biological processes throughout the progression of an epidemic outbreak and are also influenced by evolving data measurement bias. Through iterative updates of a set of weighted simulated trajectories based on observed data, this framework enables the estimation of posterior distributions for these parameters, thereby capturing their temporal variability and associated uncertainties. Through simulation studies, we showcase the efficacy of SMC in accurately tracking the evolving dynamics of epidemics while appropriately accounting for uncertainties. Moreover, we delve into practical considerations and challenges inherent in implementing SMC for parameter estimation within dynamic epidemiological settings, areas where the substantial computational capabilities of high-performance computing resources can be usefully brought to bear.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {Applications (stat.AP),Computation (stat.CO),FOS: Computer and information sciences,Methodology (stat.ME)}
}

@techreport{fergusonReportImpactNonpharmaceutical2020,
  title = {Report 9: {{Impact}} of Non-Pharmaceutical Interventions ({{NPIs}}) to Reduce {{COVID19}} Mortality and Healthcare Demand},
  shorttitle = {Report 9},
  author = {Ferguson, N and Laydon, D and Nedjati Gilani, G and Imai, N and Ainslie, K and Baguelin, M and Bhatia, S and Boonyasiri, A and Cucunuba Perez, {\relax ZULMA} and {Cuomo-Dannenburg}, G and Dighe, A and Dorigatti, I and Fu, H and Gaythorpe, K and Green, W and Hamlet, A and Hinsley, W and Okell, L and Van Elsland, S and Thompson, H and Verity, R and Volz, E and Wang, H and Wang, Y and Walker, P and Winskill, P and Whittaker, C and Donnelly, C and Riley, S and Ghani, A},
  year = {2020},
  month = mar,
  institution = {Imperial College London},
  doi = {10.25561/77482},
  urldate = {2023-09-09},
  abstract = {The global impact of COVID-19 has been profound, and the public health threat it represents is the most serious seen in a respiratory virus since the 1918 H1N1 influenza pandemic. Here we present the results of epidemiological modelling which has informed policymaking in the UK and other countries in recent weeks. In the absence of a COVID-19 vaccine, we assess the potential role of a number of public health measures -- so-called non-pharmaceutical interventions (NPIs) -- aimed at reducing contact rates in the population and thereby reducing transmission of the virus. In the results presented here, we apply a previously published microsimulation model to two countries: the UK (Great Britain specifically) and the US. We conclude that the effectiveness of any one intervention in isolation is likely to be limited, requiring multiple interventions to be combined to have a substantial impact on transmission.},
  collaborator = {{Medical Research Council (MRC)}},
  langid = {english},
  keywords = {Coronavirus,COVID19,healthcare demand,Mortality,Non-pharmaceutical interventions},
  file = {/Users/nicsteyn/Documents/Zotero/storage/LBKM8T5W/Ferguson et al. - 2020 - Report 9 Impact of non-pharmaceutical interventio.pdf}
}

@article{flaxmanEstimatingEffectsNonpharmaceutical2020,
  title = {Estimating the Effects of Non-Pharmaceutical Interventions on {{COVID-19}} in {{Europe}}},
  author = {Flaxman, Seth and Mishra, Swapnil and Gandy, Axel and Unwin, H. Juliette T. and Mellan, Thomas A. and Coupland, Helen and Whittaker, Charles and Zhu, Harrison and Berah, Tresnia and Eaton, Jeffrey W. and Monod, M{\'e}lodie and Ghani, Azra C. and Donnelly, Christl A. and Riley, Steven and Vollmer, Michaela A. C. and Ferguson, Neil M. and Okell, Lucy C. and Bhatt, Samir},
  year = {2020},
  month = aug,
  journal = {Nature},
  volume = {584},
  number = {7820},
  pages = {257--261},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-020-2405-7},
  urldate = {2024-04-17},
  abstract = {Following the detection of the new coronavirus1 severe acute respiratory syndrome coronavirus~2 (SARS-CoV-2) and its spread outside of China, Europe has experienced large epidemics of coronavirus disease~2019 (COVID-19). In response, many European countries have implemented non-pharmaceutical interventions, such as the closure of schools and national lockdowns. Here we study the effect of major interventions across 11~European countries for the period from the start of the COVID-19 epidemics in February 2020~until 4~May 2020, when lockdowns started to be lifted. Our model calculates backwards from observed deaths to estimate transmission that occurred several weeks previously, allowing for the time lag between infection and death. We use partial pooling of information between countries, with both individual and shared effects on the time-varying reproduction number (Rt). Pooling allows for more information to be used, helps to overcome idiosyncrasies in the data and enables more-timely estimates. Our model relies on fixed estimates of some epidemiological parameters (such as the infection fatality rate), does not include importation or subnational variation and assumes that changes in Rt are an immediate response to interventions rather than gradual changes in behaviour. Amidst the ongoing pandemic, we rely on death data that are incomplete, show systematic biases in reporting and are subject to future consolidation. We estimate that---for all of the countries we consider here---current interventions have been sufficient to drive Rt below~1 (probability Rt~{$<~$}1.0 is greater than 99\%) and achieve control of the epidemic. We estimate that across all 11~countries combined, between 12 and 15~million individuals were infected with SARS-CoV-2 up to 4 May 2020, representing between 3.2\% and 4.0\% of the population. Our results show that major non-pharmaceutical interventions---and lockdowns in particular---have had a large effect on reducing transmission. Continued intervention should be considered to keep transmission of SARS-CoV-2 under control.},
  copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Epidemiology,Respiratory tract diseases,SARS-CoV-2,Viral infection},
  file = {/Users/nicsteyn/Documents/Zotero/storage/BLXBC8XH/Flaxman et al. - 2020 - Estimating the effects of non-pharmaceutical inter.pdf}
}

@article{fraserEstimatingIndividualHousehold2007,
  title = {Estimating {{Individual}} and {{Household Reproduction Numbers}} in an {{Emerging Epidemic}}},
  author = {Fraser, Christophe},
  editor = {Galvani, Alison},
  year = {2007},
  month = aug,
  journal = {PLoS ONE},
  volume = {2},
  number = {8},
  pages = {e758},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0000758},
  urldate = {2024-10-04},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/N6E6ZA22/Fraser - 2007 - Estimating Individual and Household Reproduction N.pdf}
}

@article{fraserInfluenzaTransmissionHouseholds2011,
  title = {Influenza {{Transmission}} in {{Households During}} the 1918 {{Pandemic}}},
  author = {Fraser, Christophe and Cummings, Derek A. T. and Klinkenberg, Don and Burke, Donald S. and Ferguson, Neil M.},
  year = {2011},
  month = sep,
  journal = {American Journal of Epidemiology},
  volume = {174},
  number = {5},
  pages = {505--514},
  issn = {0002-9262},
  doi = {10.1093/aje/kwr122},
  urldate = {2024-04-17},
  abstract = {Analysis of historical data has strongly shaped our understanding of the epidemiology of pandemic influenza and informs analysis of current and future epidemics. Here, the authors analyzed previously unpublished documents from a large household survey of the ``Spanish'' H1N1 influenza pandemic, conducted in 1918, for the first time quantifying influenza transmissibility at the person-to-person level during that most lethal of pandemics. The authors estimated a low probability of person-to-person transmission relative to comparable estimates from seasonal influenza and other directly transmitted infections but similar to recent estimates from the 2009 H1N1 pandemic. The authors estimated a very low probability of asymptomatic infection, a previously unknown parameter for this pandemic, consistent with an unusually virulent virus. The authors estimated a high frequency of prior immunity that they attributed to a largely unreported influenza epidemic in the spring of 1918 (or perhaps to cross-reactive immunity). Extrapolating from this finding, the authors hypothesize that prior immunity partially protected some populations from the worst of the fall pandemic and helps explain differences in attack rates between populations. Together, these analyses demonstrate that the 1918 influenza virus, though highly virulent, was only moderately transmissible and thus in a modern context would be considered controllable.},
  file = {/Users/nicsteyn/Documents/Zotero/storage/QWSUBDXX/Fraser et al. - 2011 - Influenza Transmission in Households During the 19.pdf}
}

@book{gelmanBayesianDataAnalysis2014,
  title = {Bayesian Data Analysis},
  author = {Gelman, Andrew},
  year = {2014},
  series = {Chapman \& {{Hall}}/{{CRC}} Texts in Statistical Science},
  edition = {Third edition.},
  publisher = {CRC Press},
  address = {Boca Raton},
  collaborator = {Carlin, John B. and Stern, Hal Steven and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
  langid = {english},
  lccn = {QA279.5 BAY 2014},
  keywords = {Bayesian statistical decision theory}
}

@article{gelmanInferenceIterativeSimulation1992,
  title = {Inference from {{Iterative Simulation Using Multiple Sequences}}},
  author = {Gelman, Andrew and Rubin, Donald B.},
  year = {1992},
  month = nov,
  journal = {Statistical Science},
  volume = {7},
  number = {4},
  pages = {457--472},
  publisher = {Institute of Mathematical Statistics},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/ss/1177011136},
  urldate = {2024-10-25},
  abstract = {The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were continued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normality after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random-effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients.},
  keywords = {Bayesian inference,Convergence of stochastic processes,ECM,EM,Gibbs sampler,importance sampling,Metropolis algorithm,multiple imputation,random-effects model,SIR},
  file = {/Users/nicsteyn/Documents/Zotero/storage/GUA3XXGJ/Gelman and Rubin - 1992 - Inference from Iterative Simulation Using Multiple.pdf}
}

@article{gneitingStrictlyProperScoring2007,
  title = {Strictly {{Proper Scoring Rules}}, {{Prediction}}, and {{Estimation}}},
  author = {Gneiting, Tilmann and Raftery, Adrian E},
  year = {2007},
  month = mar,
  journal = {Journal of the American Statistical Association},
  volume = {102},
  number = {477},
  pages = {359--378},
  publisher = {ASA Website},
  issn = {0162-1459},
  doi = {10.1198/016214506000001437},
  urldate = {2024-09-13},
  abstract = {Scoring rules assess the quality of probabilistic forecasts, by assigning a numerical score based on the predictive distribution and on the event or value that materializes. A scoring rule is proper if the forecaster maximizes the expected score for an observation drawn from the distributionF if he or she issues the probabilistic forecast F, rather than G {$\neq$} F. It is strictly proper if the maximum is unique. In prediction problems, proper scoring rules encourage the forecaster to make careful assessments and to be honest. In estimation problems, strictly proper scoring rules provide attractive loss and utility functions that can be tailored to the problem at hand. This article reviews and develops the theory of proper scoring rules on general probability spaces, and proposes and discusses examples thereof. Proper scoring rules derive from convex functions and relate to information measures, entropy functions, and Bregman divergences. In the case of categorical variables, we prove a rigorous version of the Savage representation. Examples of scoring rules for probabilistic forecasts in the form of predictive densities include the logarithmic, spherical, pseudospherical, and quadratic scores. The continuous ranked probability score applies to probabilistic forecasts that take the form of predictive cumulative distribution functions. It generalizes the absolute error and forms a special case of a new and very general type of score, the energy score. Like many other scoring rules, the energy score admits a kernel representation in terms of negative definite functions, with links to inequalities of Hoeffding type, in both univariate and multivariate settings. Proper scoring rules for quantile and interval forecasts are also discussed. We relate proper scoring rules to Bayes factors and to cross-validation, and propose a novel form of cross-validation known as random-fold cross-validation. A case study on probabilistic weather forecasts in the North American Pacific Northwest illustrates the importance of propriety. We note optimum score approaches to point and quantile estimation, and propose the intuitively appealing interval score as a utility function in interval estimation that addresses width as well as coverage.},
  file = {/Users/nicsteyn/Documents/Zotero/storage/TUMDDF68/Gneiting and Raftery - 2007 - Strictly Proper Scoring Rules, Prediction, and Est.pdf}
}

@article{gordonNovelApproachNonlinear1993,
  title = {Novel Approach to Nonlinear/Non-{{Gaussian Bayesian}} State Estimation},
  author = {Gordon, N. J. and Salmond, D. J. and Smith, A. F. M.},
  year = {1993},
  month = apr,
  journal = {IEE Proceedings F (Radar and Signal Processing)},
  volume = {140},
  number = {2},
  pages = {107--113},
  publisher = {IET Digital Library},
  issn = {2053-9045},
  doi = {10.1049/ip-f-2.1993.0015},
  urldate = {2023-09-09},
  abstract = {An algorithm, the bootstrap filter, is proposed for implementing recursive Bayesian filters. The required density of the state vector is represented as a set of random samples, which are updated and propagated by the algorithm. The method is not restricted by assumptions of linearity or Gaussian noise: it may be applied to any state transition or measurement model. A simulation example of the bearings only tracking problem is presented. This simulation includes schemes for improving the efficiency of the basic algorithm. For this example, the performance of the bootstrap filter is greatly superior to the standard extended Kalman filter.},
  langid = {english},
  keywords = {notion},
  file = {/Users/nicsteyn/Documents/Zotero/storage/CSLFRCMR/ip-f-2.1993.html}
}

@article{gosticPracticalConsiderationsMeasuring2020,
  title = {Practical Considerations for Measuring the Effective Reproductive Number, {{Rt}}},
  author = {Gostic, Katelyn M. and McGough, Lauren and Baskerville, Edward B. and Abbott, Sam and Joshi, Keya and Tedijanto, Christine and Kahn, Rebecca and Niehus, Rene and Hay, James A. and Salazar, Pablo M. De and Hellewell, Joel and Meakin, Sophie and Munday, James D. and Bosse, Nikos I. and Sherrat, Katharine and Thompson, Robin N. and White, Laura F. and Huisman, Jana S. and Scire, J{\'e}r{\'e}mie and Bonhoeffer, Sebastian and Stadler, Tanja and Wallinga, Jacco and Funk, Sebastian and Lipsitch, Marc and Cobey, Sarah},
  year = {2020},
  month = dec,
  journal = {PLOS Computational Biology},
  volume = {16},
  number = {12},
  pages = {e1008409},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008409},
  urldate = {2023-09-12},
  abstract = {Estimation of the effective reproductive number Rt is important for detecting changes in disease transmission over time. During the Coronavirus Disease 2019 (COVID-19) pandemic, policy makers and public health officials are using Rt to assess the effectiveness of interventions and to inform policy. However, estimation of Rt from available data presents several challenges, with critical implications for the interpretation of the course of the pandemic. The purpose of this document is to summarize these challenges, illustrate them with examples from synthetic data, and, where possible, make recommendations. For near real-time estimation of Rt, we recommend the approach of Cori and colleagues, which uses data from before time t and empirical estimates of the distribution of time between infections. Methods that require data from after time t, such as Wallinga and Teunis, are conceptually and methodologically less suited for near real-time estimation, but may be appropriate for retrospective analyses of how individuals infected at different time points contributed to the spread. We advise caution when using methods derived from the approach of Bettencourt and Ribeiro, as the resulting Rt estimates may be biased if the underlying structural assumptions are not met. Two key challenges common to all approaches are accurate specification of the generation interval and reconstruction of the time series of new infections from observations occurring long after the moment of transmission. Naive approaches for dealing with observation delays, such as subtracting delays sampled from a distribution, can introduce bias. We provide suggestions for how to mitigate this and other technical challenges and highlight open problems in Rt estimation.},
  langid = {english},
  keywords = {Convolution,COVID 19,Distribution curves,Epidemiological methods and statistics,Epidemiology,notion,Pandemics,Valleys,Virus testing},
  file = {/Users/nicsteyn/Documents/Zotero/storage/FFIIQRG2/Gostic et al. - 2020 - Practical considerations for measuring the effecti.pdf}
}

@article{gressaniEpiLPSFastFlexible2022,
  title = {{{EpiLPS}}: {{A}} Fast and Flexible {{Bayesian}} Tool for Estimation of the Time-Varying Reproduction Number},
  shorttitle = {{{EpiLPS}}},
  author = {Gressani, Oswaldo and Wallinga, Jacco and Althaus, Christian L. and Hens, Niel and Faes, Christel},
  year = {2022},
  month = oct,
  journal = {PLOS Computational Biology},
  volume = {18},
  number = {10},
  pages = {e1010618},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1010618},
  urldate = {2024-04-18},
  abstract = {In infectious disease epidemiology, the instantaneous reproduction number R t is a time-varying parameter defined as the average number of secondary infections generated by an infected individual at time t. It is therefore a crucial epidemiological statistic that assists public health decision makers in the management of an epidemic. We present a new Bayesian tool (EpiLPS) for robust estimation of the time-varying reproduction number. The proposed methodology smooths the epidemic curve and allows to obtain (approximate) point estimates and credible intervals of R t by employing the renewal equation, using Bayesian P-splines coupled with Laplace approximations of the conditional posterior of the spline vector. Two alternative approaches for inference are presented: (1) an approach based on a maximum a posteriori argument for the model hyperparameters, delivering estimates of R t in only a few seconds; and (2) an approach based on a Markov chain Monte Carlo (MCMC) scheme with underlying Langevin dynamics for efficient sampling of the posterior target distribution. Case counts per unit of time are assumed to follow a negative binomial distribution to account for potential overdispersion in the data that would not be captured by a classic Poisson model. Furthermore, after smoothing the epidemic curve, a ``plug-in'' estimate of the reproduction number can be obtained from the renewal equation yielding a closed form expression of R t as a function of the spline parameters. The approach is extremely fast and free of arbitrary smoothing assumptions. EpiLPS is applied on data of SARS-CoV-1 in Hong-Kong (2003), influenza A H1N1 (2009) in the USA and on the SARS-CoV-2 pandemic (2020-2021) for Belgium, Portugal, Denmark and France.},
  langid = {english},
  keywords = {Algorithms,Approximation methods,Epidemiological methods and statistics,Epidemiology,Infectious disease epidemiology,Influenza,Pandemics,Time domain analysis},
  file = {/Users/nicsteyn/Documents/Zotero/storage/8Z3A8L6Z/Gressani et al. - 2022 - EpiLPS A fast and flexible Bayesian tool for esti.pdf}
}

@article{haugRankingEffectivenessWorldwide2020,
  title = {Ranking the Effectiveness of Worldwide {{COVID-19}} Government Interventions},
  author = {Haug, Nina and Geyrhofer, Lukas and Londei, Alessandro and Dervic, Elma and {Desvars-Larrive}, Am{\'e}lie and Loreto, Vittorio and Pinior, Beate and Thurner, Stefan and Klimek, Peter},
  year = {2020},
  month = dec,
  journal = {Nature Human Behaviour},
  volume = {4},
  number = {12},
  pages = {1303--1312},
  publisher = {Nature Publishing Group},
  issn = {2397-3374},
  doi = {10.1038/s41562-020-01009-0},
  urldate = {2023-09-12},
  abstract = {Assessing the effectiveness of non-pharmaceutical interventions (NPIs) to mitigate the spread of SARS-CoV-2 is critical to inform future preparedness response plans. Here we quantify the impact of 6,068\,hierarchically coded NPIs implemented in 79\,territories on the effective reproduction number, Rt, of COVID-19. We propose a modelling approach that combines four computational techniques merging statistical, inference and artificial intelligence tools. We validate our findings with two external datasets recording 42,151\,additional NPIs from 226\,countries. Our results indicate that a suitable combination of NPIs is necessary to curb the spread of the virus. Less disruptive and costly NPIs can be as effective as more intrusive, drastic, ones (for example, a national lockdown). Using country-specific `what-if' scenarios, we assess how the effectiveness of NPIs depends on the local context such as timing of their adoption, opening the way for forecasting the effectiveness of future interventions.},
  copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Epidemiology,Viral infection},
  file = {/Users/nicsteyn/Documents/Zotero/storage/28E65PUI/Haug et al. - 2020 - Ranking the effectiveness of worldwide COVID-19 go.pdf}
}

@article{hendyMathematicalModellingInform2021,
  title = {Mathematical Modelling to Inform {{New Zealand}}'s {{COVID-19}} Response},
  author = {Hendy, Shaun and Steyn, Nicholas and James, Alex and Plank, Michael J. and Hannah, Kate and Binny, Rachelle N. and Lustig, Audrey},
  year = {2021},
  month = may,
  journal = {Journal of the Royal Society of New Zealand},
  volume = {51},
  number = {sup1},
  pages = {S86-S106},
  issn = {0303-6758, 1175-8899},
  doi = {10.1080/03036758.2021.1876111},
  urldate = {2023-09-08},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/ML49DH8Q/Hendy et al. - 2021 - Mathematical modelling to inform New Zealands COV.pdf}
}

@article{hookerParameterizingStateSpace2010,
  title = {Parameterizing State--Space Models for Infectious Disease Dynamics by Generalized Profiling: Measles in {{Ontario}}},
  shorttitle = {Parameterizing State--Space Models for Infectious Disease Dynamics by Generalized Profiling},
  author = {Hooker, Giles and Ellner, Stephen P. and Roditi, Laura De Vargas and Earn, David J. D.},
  year = {2010},
  month = nov,
  journal = {Journal of The Royal Society Interface},
  volume = {8},
  number = {60},
  pages = {961--974},
  publisher = {Royal Society},
  doi = {10.1098/rsif.2010.0412},
  urldate = {2025-03-15},
  abstract = {Parameter estimation for infectious disease models is important for basic understanding (e.g. to identify major transmission pathways), for forecasting emerging epidemics, and for designing control measures. Differential equation models are often used, but statistical inference for differential equations suffers from numerical challenges and poor agreement between observational data and deterministic models. Accounting for these departures via stochastic model terms requires full specification of the probabilistic dynamics, and computationally demanding estimation methods. Here, we demonstrate the utility of an alternative approach, generalized profiling, which provides robustness to violations of a deterministic model without needing to specify a complete probabilistic model. We introduce novel means for estimating the robustness parameters and for statistical inference in this framework. The methods are applied to a model for pre-vaccination measles incidence in Ontario, and we demonstrate the statistical validity of our inference through extensive simulation. The results confirm that school term versus summer drives seasonality of transmission, but we find no effects of short school breaks and the estimated basic reproductive ratio {$R$}0 greatly exceeds previous estimates. The approach applies naturally to any system for which candidate differential equations are available, and avoids many challenges that have limited Monte Carlo inference for state--space models.},
  keywords = {differential equation model,generalized profiling,measles,state-space model},
  file = {/Users/nicsteyn/Documents/Zotero/storage/UW8LBC5L/Hooker et al. - 2010 - Parameterizing statespace models for infectious d.pdf}
}

@article{huismanEstimationWorldwideMonitoring2022,
  title = {Estimation and Worldwide Monitoring of the Effective Reproductive Number of {{SARS-CoV-2}}},
  author = {Huisman, Jana S and Scire, J{\'e}r{\'e}mie and Angst, Daniel C and Li, Jinzhou and Neher, Richard A and Maathuis, Marloes H and Bonhoeffer, Sebastian and Stadler, Tanja},
  editor = {Davenport, Miles P},
  year = {2022},
  month = aug,
  journal = {eLife},
  volume = {11},
  pages = {e71345},
  publisher = {eLife Sciences Publications, Ltd},
  issn = {2050-084X},
  doi = {10.7554/eLife.71345},
  urldate = {2024-02-05},
  abstract = {The effective reproductive number Re is a key indicator of the growth of an epidemic. Since the start of the SARS-CoV-2 pandemic, many methods and online dashboards have sprung up to monitor this number through time. However, these methods are not always thoroughly tested, correctly placed in time, or are overly confident during high incidence periods. Here, we present a method for timely estimation of Re, applied to COVID-19 epidemic data from 170 countries. We thoroughly evaluate the method on simulated data, and present an intuitive web interface for interactive data exploration. We show that, in early 2020, in the majority of countries the estimated Re dropped below 1 only after the introduction of major non-pharmaceutical interventions. For Europe the implementation of non-pharmaceutical interventions was broadly associated with reductions in the estimated Re. Globally though, relaxing non-pharmaceutical interventions had more varied effects on subsequent Re estimates. Our framework is useful to inform governments and the general public on the status of epidemics in their country, and is used as the official source of Re estimates for SARS-CoV-2 in Switzerland. It further allows detailed comparison between countries and in relation to covariates such as implemented public health policies, mobility, behaviour, or weather data.},
  keywords = {infectious disease,public health surveillance,reproductive number,SARS-CoV-2},
  file = {/Users/nicsteyn/Documents/Zotero/storage/BVLBGIIB/Huisman et al. - 2022 - Estimation and worldwide monitoring of the effecti.pdf}
}

@incollection{hurzelerApproximatingMaximisingLikelihood2001,
  title = {Approximating and {{Maximising}} the {{Likelihood}} for a {{General State-Space Model}}},
  booktitle = {Sequential {{Monte Carlo Methods}} in {{Practice}}},
  author = {H{\"u}rzeler, Markus and K{\"u}nsch, Hans R.},
  editor = {Doucet, Arnaud and {de Freitas}, Nando and Gordon, Neil},
  year = {2001},
  series = {Statistics for {{Engineering}} and {{Information Science}}},
  pages = {159--175},
  publisher = {Springer},
  address = {New York, NY},
  doi = {10.1007/978-1-4757-3437-9_8},
  urldate = {2023-09-13},
  abstract = {Assume that in a general state-space model the state transitions p(xt{\textbar}xt-1) depend on a parameter {$\tau$} and the observations densities p(yt{\textbar}xt) on a parameter {$\eta$}. These can be for instance the noise variances in the state and the observation density, or some parameters related to the mean value of these densities. Both {$\tau$} and {$\eta$} can be multi-dimensional. The combined parameter ({$\tau\prime$},{$\eta\prime$}){$\prime$} will be denoted by {\texttheta}. We discuss here the estimation of {\texttheta}. For state-space models, the Bayesian viewpoint is often adopted and prior distributions for the unknown parameters are introduced. We discuss this approach briefly, but concentrate mainly on the frequentist approach where one has to compute and maximise the likelihood. Exact methods are usually not feasible, but the Monte Carlo methods allow us to approximate the likelihood function.},
  isbn = {978-1-4757-3437-9},
  langid = {english}
}

@article{ionidesInferenceDynamicLatent2015,
  title = {Inference for Dynamic and Latent Variable Models via Iterated, Perturbed {{Bayes}} Maps},
  author = {Ionides, Edward L. and Nguyen, Dao and Atchad{\'e}, Yves and Stoev, Stilian and King, Aaron A.},
  year = {2015},
  month = jan,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {112},
  number = {3},
  pages = {719--724},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1410597112},
  urldate = {2025-02-24},
  abstract = {Significance             Many scientific challenges involve the study of stochastic dynamic systems for which only noisy or incomplete measurements are available. Inference for partially observed Markov process models provides a framework for formulating and answering questions about these systems. Except when the system is small, or approximately linear and Gaussian, state-of-the-art statistical methods are required to make efficient use of available data. Evaluation of the likelihood for a partially observed Markov process model can be formulated as a filtering problem. Iterated filtering algorithms carry out repeated Monte Carlo filtering operations to maximize the likelihood. We develop a new theoretical framework for iterated filtering and construct a new algorithm that dramatically outperforms previous approaches on a challenging inference problem in disease ecology.           ,              Iterated filtering algorithms are stochastic optimization procedures for latent variable models that recursively combine parameter perturbations with latent variable reconstruction. Previously, theoretical support for these algorithms has been based on the use of conditional moments of perturbed parameters to approximate derivatives of the log likelihood function. Here, a theoretical approach is introduced based on the convergence of an iterated Bayes map. An algorithm supported by this theory displays substantial numerical improvement on the computational challenge of inferring parameters of a partially observed Markov process.},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/NVBL9WWW/Ionides et al. - 2015 - Inference for dynamic and latent variable models v.pdf}
}

@article{ionidesInferenceNonlinearDynamical2006,
  title = {Inference for Nonlinear Dynamical Systems},
  author = {Ionides, E. L. and Bret{\'o}, C. and King, A. A.},
  year = {2006},
  month = dec,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {103},
  number = {49},
  pages = {18438--18443},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0603181103},
  urldate = {2025-02-24},
  abstract = {Nonlinear stochastic dynamical systems are widely used to model systems across the sciences and engineering. Such models are natural to formulate and can be analyzed mathematically and numerically. However, difficulties associated with inference from time-series data about unknown parameters in these models have been a constraint on their application. We present a new method that makes maximum likelihood estimation feasible for partially-observed nonlinear stochastic dynamical systems (also known as state-space models) where this was not previously the case. The method is based on a sequence of filtering operations which are shown to converge to a maximum likelihood parameter estimate. We make use of recent advances in nonlinear filtering in the implementation of the algorithm. We apply the method to the study of cholera in Bangladesh. We construct confidence intervals, perform residual analysis, and apply other diagnostics. Our analysis, based upon a model capturing the intrinsic nonlinear dynamics of the system, reveals some effects overlooked by previous studies.},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/EA3AY59L/Ionides et al. - 2006 - Inference for nonlinear dynamical systems.pdf}
}

@article{ionidesIteratedFiltering2011,
  title = {Iterated Filtering},
  author = {Ionides, Edward L. and Bhadra, Anindya and Atchad{\'e}, Yves and King, Aaron},
  year = {2011},
  month = jun,
  journal = {The Annals of Statistics},
  volume = {39},
  number = {3},
  issn = {0090-5364},
  doi = {10.1214/11-AOS886},
  urldate = {2025-02-24},
  file = {/Users/nicsteyn/Documents/Zotero/storage/DABL5S2S/Ionides et al. - 2011 - Iterated filtering.pdf}
}

@article{jordanEvaluatingProbabilisticForecasts2019,
  title = {Evaluating {{Probabilistic Forecasts}} with {{scoringRules}}},
  author = {Jordan, Alexander and Kr{\"u}ger, Fabian and Lerch, Sebastian},
  year = {2019},
  month = aug,
  journal = {Journal of Statistical Software},
  volume = {90},
  pages = {1--37},
  issn = {1548-7660},
  doi = {10.18637/jss.v090.i12},
  urldate = {2025-01-30},
  abstract = {Probabilistic forecasts in the form of probability distributions over future events have become popular in several fields including meteorology, hydrology, economics, and demography. In typical applications, many alternative statistical models and data sources can be used to produce probabilistic forecasts. Hence, evaluating and selecting among competing methods is an important task. The scoringRules package for R provides functionality for comparative evaluation of probabilistic models based on proper scoring rules, covering a wide range of situations in applied work. This paper discusses implementation and usage details, presents case studies from meteorology and economics, and points to the relevant background literature.},
  copyright = {Copyright (c) 2019 Alexander Jordan, Fabian Kr{\"u}ger, Sebastian Lerch},
  langid = {english},
  keywords = {comparative evaluation,ensemble forecasts,out-of-sample evaluation,predictive distributions,proper scoring rules,R,score computation},
  file = {/Users/nicsteyn/Documents/Zotero/storage/V6MVFI6A/Jordan et al. - 2019 - Evaluating Probabilistic Forecasts with scoringRul.pdf}
}

@misc{judgeEpiFusionJointInference2023,
  title = {{{EpiFusion}}: {{Joint}} Inference of the Effective Reproduction Number by Integrating Phylodynamic and Epidemiological Modelling with Particle Filtering},
  shorttitle = {{{EpiFusion}}},
  author = {Judge, Ciara and Vaughan, Timothy and Russell, Timothy and Abbott, Sam and du Plessis, Louis and Stadler, Tanja and Brady, Oliver and Hill, Sarah},
  year = {2023},
  month = dec,
  primaryclass = {New Results},
  pages = {2023.12.18.572106},
  publisher = {bioRxiv},
  doi = {10.1101/2023.12.18.572106},
  urldate = {2024-09-02},
  abstract = {Accurately estimating the effective reproduction number (Rt) of a circulating pathogen is a fundamental challenge in the study of infectious disease. The fields of epidemiology and pathogen phylodynamics both share this goal, but to date, methodologies and data employed by each remain largely distinct. Here we present EpiFusion: a joint approach that can be used to harness the complementary strengths of each field to improve estimation of outbreak dynamics for large and poorly sampled epidemics, such as arboviral or respiratory outbreaks, and validate it for retrospective analysis. We propose a model of Rt that estimates outbreak trajectories conditional upon both phylodynamic (time-scaled trees estimated from genetic sequences) and epidemiological (case incidence) data. We simulate stochastic outbreak trajectories that are weighted according to epidemiological and phylodynamic observation models and fit using particle Markov Chain Monte Carlo. To assess performance, we test EpiFusion on simulated outbreaks in which transmission and/or surveillance rapidly changes and find that using EpiFusion to combine epidemiological and phylodynamic data maintains accuracy and increases certainty in trajectory and Rt estimates, compared to when each data type is used alone. Finally, we benchmark EpiFusion's performance against existing methods to estimate Rt and demonstrate advances in efficiency and accuracy. Importantly, our approach scales efficiently with dataset size, including the use of phylogenetic trees generated from large genomic datasets. EpiFusion is designed to accommodate future extensions that will improve its utility, such as introduction of population structure, accommodations for phylogenetic uncertainty, and the ability to weight the contributions of genomic or case incidence to the inference. Author Summary Understanding infectious disease spread is fundamental to protecting public health, but can be challenging as disease spread is a phenomenon that cannot be directly observed. So, epidemiologists use data in conjunction with mathematical models to estimate disease dynamics. Often, combinations of different models and data can be used to answer the same questions -- for example `traditional' epidemiology commonly uses case incidence data (the number of people who have tested positive for a disease at a certain time) whereas phylodynamic models use pathogen genomic sequence data and our knowledge of their evolution to model disease population dynamics. Each of these approaches have strengths and limitations, and data of each type can be sparse or biased, particularly in rapidly developing outbreaks or lower-middle income countries. An increasing number of approaches attempt to fix this problem by incorporating diverse concepts and data types together in their models. We aim to contribute to this movement by introducing EpiFusion, a modelling framework that makes improvements on efficiency and temporal resolution. EpiFusion uses particle filtering to simulate epidemic trajectories over time and weight their likelihood according to both case incidence data and a phylogenetic tree using separate observation models, resulting in the inference of trajectories in agreement with both sets of data. Improvements in our ability to accurately and confidently model pathogen spread help us to respond to infectious disease outbreaks and improve public health.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/SIIXMLX5/Judge et al. - 2023 - EpiFusion Joint inference of the effective reprod.pdf}
}

@article{kantasParticleMethodsParameter2015,
  title = {On {{Particle Methods}} for {{Parameter Estimation}} in {{State-Space Models}}},
  author = {Kantas, Nikolas and Doucet, Arnaud and Singh, Sumeetpal S. and Maciejowski, Jan and Chopin, Nicolas},
  year = {2015},
  month = aug,
  journal = {Statistical Science},
  volume = {30},
  number = {3},
  pages = {328--351},
  publisher = {Institute of Mathematical Statistics},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/14-STS511},
  urldate = {2023-09-13},
  abstract = {Nonlinear non-Gaussian state-space models are ubiquitous in statistics, econometrics, information engineering and signal processing. Particle methods, also known as Sequential Monte Carlo (SMC) methods, provide reliable numerical approximations to the associated state inference problems. However, in most applications, the state-space model of interest also depends on unknown static parameters that need to be estimated from the data. In this context, standard particle methods fail and it is necessary to rely on more sophisticated algorithms. The aim of this paper is to present a comprehensive review of particle methods that have been proposed to perform static parameter estimation in state-space models. We discuss the advantages and limitations of these methods and illustrate their performance on simple models.},
  keywords = {Bayesian inference,maximum likelihood inference,particle filtering,sequential Monte Carlo,state-space models},
  file = {/Users/nicsteyn/Documents/Zotero/storage/LMIRHCPB/Kantas et al. - 2015 - On Particle Methods for Parameter Estimation in St.pdf}
}

@article{kingStatisticalInferencePartially2016,
  title = {Statistical {{Inference}} for {{Partially Observed Markov Processes}} via the {{{\emph{R}}}} {{Package}} {\textbf{Pomp}}},
  author = {King, Aaron A. and Nguyen, Dao and Ionides, Edward L.},
  year = {2016},
  journal = {Journal of Statistical Software},
  volume = {69},
  number = {12},
  issn = {1548-7660},
  doi = {10.18637/jss.v069.i12},
  urldate = {2025-02-24},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/GRM9CSME/King et al. - 2016 - Statistical Inference for Partially Observed Marko.pdf}
}

@article{klepacSixChallengesEradication2015,
  title = {Six Challenges in the Eradication of Infectious Diseases},
  author = {Klepac, Petra and Funk, Sebastian and Hollingsworth, T. Deirdre and Metcalf, C. Jessica E. and Hampson, Katie},
  year = {2015},
  month = mar,
  journal = {Epidemics},
  series = {Challenges in {{Modelling Infectious Disease Dynamics}}},
  volume = {10},
  pages = {97--101},
  issn = {1755-4365},
  doi = {10.1016/j.epidem.2014.12.001},
  urldate = {2024-10-25},
  abstract = {Eradication and elimination are increasingly a part of the global health agenda. Once control measures have driven infection to low levels, the ecology of disease may change posing challenges for eradication efforts. These challenges vary from identifying pockets of susceptibles, improving monitoring during and after the endgame, to quantifying the economics of disease eradication versus sustained control, all of which are shaped and influenced by processes of loss of immunity, susceptible build-up, emergence of resistance, population heterogeneities and non-compliance with control measures. Here we discuss how modelling can be used to address these challenges.},
  keywords = {Dynamics,Elimination,Heterogeneity,Modelling,Surveillance},
  file = {/Users/nicsteyn/Documents/Zotero/storage/M3EW5WJX/Klepac et al. - 2015 - Six challenges in the eradication of infectious di.pdf;/Users/nicsteyn/Documents/Zotero/storage/RT39GLMP/S175543651400070X.html}
}

@article{koyamaEstimatingTimevaryingReproduction2021,
  title = {Estimating the Time-Varying Reproduction Number of {{COVID-19}} with a State-Space Method},
  author = {Koyama, Shinsuke and Horie, Taiki and Shinomoto, Shigeru},
  year = {2021},
  month = jan,
  journal = {PLOS Computational Biology},
  volume = {17},
  number = {1},
  pages = {e1008679},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008679},
  urldate = {2024-09-05},
  abstract = {After slowing down the spread of the novel coronavirus COVID-19, many countries have started to relax their confinement measures in the face of critical damage to socioeconomic structures. At this stage, it is desirable to monitor the degree to which political measures or social affairs have exerted influence on the spread of disease. Though it is difficult to trace back individual transmission of infections whose incubation periods are long and highly variable, estimating the average spreading rate is possible if a proper mathematical model can be devised to analyze daily event-occurrences. To render an accurate assessment, we have devised a state-space method for fitting a discrete-time variant of the Hawkes process to a given dataset of daily confirmed cases. The proposed method detects changes occurring in each country and assesses the impact of social events in terms of the temporally varying reproduction number, which corresponds to the average number of cases directly caused by a single infected case. Moreover, the proposed method can be used to predict the possible consequences of alternative political measures. This information can serve as a reference for behavioral guidelines that should be adopted according to the varying risk of infection.},
  langid = {english},
  keywords = {Algorithms,COVID 19,Differential equations,Forecasting,Italy,Japan,Mathematical models,Monte Carlo method},
  file = {/Users/nicsteyn/Documents/Zotero/storage/2WLNFJ79/Koyama et al. - 2021 - Estimating the time-varying reproduction number of.pdf}
}

@article{lawlessAdjustmentsReportingDelays1994,
  title = {Adjustments for {{Reporting Delays}} and the {{Prediction}} of {{Occurred}} but {{Not Reported Events}}},
  author = {Lawless, J. F.},
  year = {1994},
  journal = {The Canadian Journal of Statistics / La Revue Canadienne de Statistique},
  volume = {22},
  number = {1},
  eprint = {3315820},
  eprinttype = {jstor},
  pages = {15--31},
  publisher = {[Statistical Society of Canada, Wiley]},
  issn = {0319-5724},
  doi = {10.2307/3315820},
  urldate = {2025-03-15},
  abstract = {We consider delays that occur in the reporting of events such as cases of a reportable disease or insurance claims. Estimation of the number of events that have occurred but not yet been reported (OBNR events) is then important. Current methods of doing this do not allow random temporal fluctuations in reporting delays, and consequently, confidence or prediction limits on OBNR events tend to be too narrow. We develop an approach that uses recent reporting data and incorporates random effects, thus leading to more reasonable and robust predictions. /// Nous consid{\'e}rons les d{\'e}lais qui ont lieu dans le rapport d'{\'e}v{\'e}nements tels qu'une maladie ou une demande d'indemnit{\'e}. L'estimation du nombre d'{\'e}v{\'e}nements qui ont eu lieu mais n'ont pas encore {\'e}t{\'e} rapport{\'e}s ({\'e}v{\'e}nements OBNR) est alors importante. Les m{\'e}thodes actuelles ne permettent pas de fluctuations temporelles al{\'e}atoires dans les d{\'e}lais de rapport et par cons{\'e}quent, les limites de confiance ou de pr{\'e}vision des {\'e}v{\'e}nements OBNR ont tendance {\`a} {\^e}tre trop {\'e}troites. Nous d{\'e}veloppons une approche utilisant les donn{\'e}es de rapport r{\'e}cent et incorporant des effets al{\'e}atoires. Ainsi, les pr{\'e}visions sont plus vraisemblables et robustes.},
  file = {/Users/nicsteyn/Documents/Zotero/storage/57F7BXL4/Lawless - 1994 - Adjustments for Reporting Delays and the Predictio.pdf}
}

@article{lewnardEmergingChallengesOpportunities2019,
  title = {Emerging {{Challenges}} and {{Opportunities}} in {{Infectious Disease Epidemiology}}},
  author = {Lewnard, Joseph A and Reingold, Arthur L},
  year = {2019},
  month = may,
  journal = {American Journal of Epidemiology},
  volume = {188},
  number = {5},
  pages = {873--882},
  issn = {0002-9262},
  doi = {10.1093/aje/kwy264},
  urldate = {2024-10-04},
  abstract = {Much of the intellectual tradition of modern epidemiology stems from efforts to understand and combat chronic diseases persisting through the 20th century epidemiologic transition of countries such as the United States and United Kingdom. After decades of relative obscurity, infectious disease epidemiology has undergone an intellectual rebirth in recent years amid increasing recognition of the threat posed by both new and familiar pathogens. Here, we review the emerging coalescence of infectious disease epidemiology around a core set of study designs and statistical methods bearing little resemblance to the chronic disease epidemiology toolkit. We offer our outlook on challenges and opportunities facing the field, including the integration of novel molecular and digital information sources into disease surveillance, the assimilation of such data into models of pathogen spread, and the increasing contribution of models to public health practice. We next consider emerging paradigms in causal inference for infectious diseases, ranging from approaches to evaluating vaccines and antimicrobial therapies to the task of ascribing clinical syndromes to etiologic microorganisms, an age-old problem transformed by our increasing ability to characterize human-associated microbiota. These areas represent an increasingly important component of epidemiology training programs for future generations of researchers and practitioners.},
  file = {/Users/nicsteyn/Documents/Zotero/storage/PE3PW74F/Lewnard and Reingold - 2019 - Emerging Challenges and Opportunities in Infectiou.pdf;/Users/nicsteyn/Documents/Zotero/storage/WH8S6D2E/5381897.html}
}

@article{liRealTimeEpidemiologyAcute2024,
  title = {Real-{{Time Epidemiology}} and {{Acute Care Need Monitoring}} and {{Forecasting}} for {{COVID-19}} via {{Bayesian Sequential Monte Carlo-Leveraged Transmission Models}}},
  author = {Li, Xiaoyan and Patel, Vyom and Duan, Lujie and Mikuliak, Jalen and Basran, Jenny and Osgood, Nathaniel D.},
  year = {2024},
  month = feb,
  journal = {International Journal of Environmental Research and Public Health},
  volume = {21},
  number = {2},
  pages = {193},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {1660-4601},
  doi = {10.3390/ijerph21020193},
  urldate = {2024-10-03},
  abstract = {COVID-19 transmission models have conferred great value in informing public health understanding, planning, and response. However, the pandemic also demonstrated the infeasibility of basing public health decision-making on transmission models with pre-set assumptions. No matter how favourably evidenced when built, a model with fixed assumptions is challenged by numerous factors that are difficult to predict. Ongoing planning associated with rolling back and re-instituting measures, initiating surge planning, and issuing public health advisories can benefit from approaches that allow state estimates for transmission models to be continuously updated in light of unfolding time series. A model being continuously regrounded by empirical data in this way can provide a consistent, integrated depiction of the evolving underlying epidemiology and acute care demand, offer the ability to project forward such a depiction in a fashion suitable for triggering the deployment of acute care surge capacity or public health measures, and support quantitative evaluation of tradeoffs associated with prospective interventions in light of the latest estimates of the underlying epidemiology. We describe here the design, implementation, and multi-year daily use for public health and clinical support decision-making of a particle-filtered COVID-19 compartmental model, which served Canadian federal and provincial governments via regular reporting starting in June 2020. The use of the Bayesian sequential Monte Carlo algorithm of particle filtering allows the model to be regrounded daily and adapt to new trends within daily incoming data---including test volumes and positivity rates, endogenous and travel-related cases, hospital census and admissions flows, daily counts of dose-specific vaccinations administered, measured concentration of SARS-CoV-2 in wastewater, and mortality. Important model outputs include estimates (via sampling) of the count of undiagnosed infectives, the count of individuals at different stages of the natural history of frankly and pauci-symptomatic infection, the current force of infection, effective reproductive number, and current and cumulative infection prevalence. Following a brief description of the model design, we describe how the machine learning algorithm of particle filtering is used to continually reground estimates of the dynamic model state, support a probabilistic model projection of epidemiology and health system capacity utilization and service demand, and probabilistically evaluate tradeoffs between potential intervention scenarios. We further note aspects of model use in practice as an effective reporting tool in a manner that is parameterized by jurisdiction, including the support of a scripting pipeline that permits a fully automated reporting pipeline other than security-restricted new data retrieval, including automated model deployment, data validity checks, and automatic post-scenario scripting and reporting. As demonstrated by this multi-year deployment of the Bayesian machine learning algorithm of particle filtering to provide industrial-strength reporting to inform public health decision-making across Canada, such methods offer strong support for evidence-based public health decision-making informed by ever-current articulated transmission models whose probabilistic state and parameter estimates are continually regrounded by diverse data streams.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {compartmental model,COVID-19,epidemiologic modeling,machine learning,particle filtering,projection and intervention},
  file = {/Users/nicsteyn/Documents/Zotero/storage/SBVFIL8U/Li et al. - 2024 - Real-Time Epidemiology and Acute Care Need Monitor.pdf}
}

@article{lisonGenerativeBayesianModeling2024,
  title = {Generative {{Bayesian}} Modeling to Nowcast the Effective Reproduction Number from Line List Data with Missing Symptom Onset Dates},
  author = {Lison, Adrian and Abbott, Sam and Huisman, Jana and Stadler, Tanja},
  year = {2024},
  month = apr,
  journal = {PLOS Computational Biology},
  volume = {20},
  number = {4},
  pages = {e1012021},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1012021},
  urldate = {2024-09-02},
  abstract = {The time-varying effective reproduction number Rt is a widely used indicator of transmission dynamics during infectious disease outbreaks. Timely estimates of Rt can be obtained from reported cases counted by their date of symptom onset, which is generally closer to the time of infection than the date of report. Case counts by date of symptom onset are typically obtained from line list data, however these data can have missing information and are subject to right truncation. Previous methods have addressed these problems independently by first imputing missing onset dates, then adjusting truncated case counts, and finally estimating the effective reproduction number. This stepwise approach makes it difficult to propagate uncertainty and can introduce subtle biases during real-time estimation due to the continued impact of assumptions made in previous steps. In this work, we integrate imputation, truncation adjustment, and Rt estimation into a single generative Bayesian model, allowing direct joint inference of case counts and Rt from line list data with missing symptom onset dates. We then use this framework to compare the performance of nowcasting approaches with different stepwise and generative components on synthetic line list data for multiple outbreak scenarios and across different epidemic phases. We find that under reporting delays realistic for hospitalization data (50\% of reports delayed by more than a week), intermediate smoothing, as is common practice in stepwise approaches, can bias nowcasts of case counts and Rt, which is avoided in a joint generative approach due to shared regularization of all model components. On incomplete line list data, a fully generative approach enables the quantification of uncertainty due to missing onset dates without the need for an initial multiple imputation step. In a real-world comparison using hospitalization line list data from the COVID-19 pandemic in Switzerland, we observe the same qualitative differences between approaches. The generative modeling components developed in this work have been integrated and further extended in the R package epinowcast, providing a flexible and interpretable tool for real-time surveillance.},
  langid = {english},
  keywords = {COVID 19,Hospitalizations,Pandemics,Probability distribution,Public and occupational health,Random walk,Simulation and modeling,Switzerland},
  file = {/Users/nicsteyn/Documents/Zotero/storage/Q7P27ZT4/Lison et al. - 2024 - Generative Bayesian modeling to nowcast the effect.pdf}
}

@article{liuRtestimTimevaryingReproduction2024,
  title = {Rtestim: {{Time-varying}} Reproduction Number Estimation with Trend Filtering},
  shorttitle = {Rtestim},
  author = {Liu, Jiaping and Cai, Zhenglun and Gustafson, Paul and McDonald, Daniel J.},
  year = {2024},
  month = aug,
  journal = {PLOS Computational Biology},
  volume = {20},
  number = {8},
  pages = {e1012324},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1012324},
  urldate = {2024-09-02},
  abstract = {To understand the transmissibility and spread of infectious diseases, epidemiologists turn to estimates of the instantaneous reproduction number. While many estimation approaches exist, their utility may be limited. Challenges of surveillance data collection, model assumptions that are unverifiable with data alone, and computationally inefficient frameworks are critical limitations for many existing approaches. We propose a discrete spline-based approach that solves a convex optimization problem---Poisson trend filtering---using the proximal Newton method. It produces a locally adaptive estimator for instantaneous reproduction number estimation with heterogeneous smoothness. Our methodology remains accurate even under some process misspecifications and is computationally efficient, even for large-scale data. The implementation is easily accessible in a lightweight R package rtestim.},
  langid = {english},
  keywords = {Canada,COVID 19,Epidemiological methods and statistics,Epidemiology,Influenza,Measles,Pandemics,SARS},
  file = {/Users/nicsteyn/Documents/Zotero/storage/WARTPFIE/Liu et al. - 2024 - rtestim Time-varying reproduction number estimati.pdf}
}

@article{lloyd-smithSuperspreadingEffectIndividual2005,
  title = {Superspreading and the Effect of Individual Variation on Disease Emergence},
  author = {{Lloyd-Smith}, J. O. and Schreiber, S. J. and Kopp, P. E. and Getz, W. M.},
  year = {2005},
  month = nov,
  journal = {Nature},
  volume = {438},
  number = {7066},
  pages = {355--359},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature04153},
  urldate = {2025-03-20},
  abstract = {From Typhoid Mary to SARS, it has long been known that some people spread disease more than others. But for diseases transmitted via casual contact, contagiousness arises from a plethora of social and physiological factors, so epidemiologists have tended to rely on population averages to assess a disease's potential to spread. A new analysis of outbreak data shows that individual differences in infectiousness exert powerful influences on the epidemiology of ten deadly diseases. SARS and measles (and perhaps avian influenza) show strong tendencies towards `superspreading events' that can ignite explosive epidemics --- but this same volatility makes outbreaks more likely to fizzle out. Smallpox and pneumonic plague, two potential bioterrorism agents, show steadier growth but still differ markedly from the traditional average-based view. These findings are relevant to how emerging diseases are detected and controlled.},
  copyright = {2005 Springer Nature Limited},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {/Users/nicsteyn/Documents/Zotero/storage/EN5KI6RC/Lloyd-Smith et al. - 2005 - Superspreading and the effect of individual variat.pdf}
}

@article{mcgoughNowcastingBayesianSmoothing2020,
  title = {Nowcasting by {{Bayesian Smoothing}}: {{A}} Flexible, Generalizable Model for Real-Time Epidemic Tracking},
  shorttitle = {Nowcasting by {{Bayesian Smoothing}}},
  author = {McGough, Sarah F. and Johansson, Michael A. and Lipsitch, Marc and Menzies, Nicolas A.},
  year = {2020},
  month = apr,
  journal = {PLOS Computational Biology},
  volume = {16},
  number = {4},
  pages = {e1007735},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1007735},
  urldate = {2024-10-27},
  abstract = {Achieving accurate, real-time estimates of disease activity is challenged by delays in case reporting. ``Nowcast'' approaches attempt to estimate the complete case counts for a given reporting date, using a time series of case reports that is known to be incomplete due to reporting delays. Modeling the reporting delay distribution is a common feature of nowcast approaches. However, many nowcast approaches ignore a crucial feature of infectious disease transmission---that future cases are intrinsically linked to past reported cases---and are optimized to one or two applications, which may limit generalizability. Here, we present a Bayesian approach, NobBS (Nowcasting by Bayesian Smoothing) capable of producing smooth and accurate nowcasts in multiple disease settings. We test NobBS on dengue in Puerto Rico and influenza-like illness (ILI) in the United States to examine performance and robustness across settings exhibiting a range of common reporting delay characteristics (from stable to time-varying), and compare this approach with a published nowcasting software package while investigating the features of each approach that contribute to good or poor performance. We show that introducing a temporal relationship between cases considerably improves performance when the reporting delay distribution is time-varying, and we identify trade-offs in the role of moving windows to accurately capture changes in the delay. We present software implementing this new approach (R package ``NobBS'') for widespread application and provide practical guidance on implementation.},
  langid = {english},
  keywords = {Autocorrelation,Dengue fever,Epidemiology,Infectious disease surveillance,Infectious diseases,Influenza,Probability distribution,Random walk},
  file = {/Users/nicsteyn/Documents/Zotero/storage/8D7H5DEV/McGough et al. - 2020 - Nowcasting by Bayesian Smoothing A flexible, gene.pdf}
}

@article{mckinleyInferenceEpidemicModels2009,
  title = {Inference in {{Epidemic Models}} without {{Likelihoods}}},
  author = {McKinley, Trevelyan and Cook, Alex R. and Deardon, Robert},
  year = {2009},
  month = jul,
  journal = {The International Journal of Biostatistics},
  volume = {5},
  number = {1},
  publisher = {De Gruyter},
  issn = {1557-4679},
  doi = {10.2202/1557-4679.1171},
  urldate = {2025-03-15},
  abstract = {Likelihood-based inference for epidemic models can be challenging, in part due to difficulties in evaluating the likelihood. The problem is particularly acute in models of large-scale outbreaks, and unobserved or partially observed data further complicates this process. Here we investigate the performance of Markov Chain Monte Carlo and Sequential Monte Carlo algorithms for parameter inference, where the routines are based on approximate likelihoods generated from model simulations. We compare our results to a gold-standard data-augmented MCMC for both complete and incomplete data. We illustrate our techniques using simulated epidemics as well as data from a recent outbreak of Ebola Haemorrhagic Fever in the Democratic Republic of Congo and discuss situations in which we think simulation-based inference may be preferable to likelihood-based inference.},
  copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
  langid = {english},
  keywords = {Approximate Bayesian Computation,infectious disease modelling,inference,Markov Chain Monte Carlo,Sequential Monte Carlo},
  file = {/Users/nicsteyn/Documents/Zotero/storage/KWX8JUTH/McKinley et al. - 2009 - Inference in Epidemic Models without Likelihoods.pdf}
}

@misc{MCMCChains2024,
  title = {{{MCMCChains}}},
  year = {2024},
  urldate = {2024-10-25},
  file = {/Users/nicsteyn/Documents/Zotero/storage/D52A39LC/stable.html}
}

@misc{ministryofhealthnzNewZealandCOVID192024,
  title = {New {{Zealand COVID-19 Data}}},
  author = {{Ministry of Health NZ}},
  year = {2024},
  urldate = {2024-09-13}
}

@article{nashEstimatingEpidemicReproduction2023,
  title = {Estimating the Epidemic Reproduction Number from Temporally Aggregated Incidence Data: {{A}} Statistical Modelling Approach and Software Tool},
  shorttitle = {Estimating the Epidemic Reproduction Number from Temporally Aggregated Incidence Data},
  author = {Nash, Rebecca K. and Bhatt, Samir and Cori, Anne and Nouvellet, Pierre},
  editor = {Lau, Eric Hy},
  year = {2023},
  month = aug,
  journal = {PLOS Computational Biology},
  volume = {19},
  number = {8},
  pages = {e1011439},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1011439},
  urldate = {2023-09-29},
  abstract = {The time-varying reproduction number (R               t               ) is an important measure of epidemic transmissibility that directly informs policy decisions and the optimisation of control measures. EpiEstim is a widely used opensource software tool that uses case incidence and the serial interval (SI, time between symptoms in a case and their infector) to estimate R               t               in real-time. The incidence and the SI distribution must be provided at the same temporal resolution, which can limit the applicability of EpiEstim and other similar methods, e.g. for contexts where the time window of incidence reporting is longer than the mean SI. In the EpiEstim R package, we implement an expectation-maximisation algorithm to reconstruct daily incidence from temporally aggregated data, from which R               t               can then be estimated. We assess the validity of our method using an extensive simulation study and apply it to COVID-19 and influenza data. For all datasets, the influence of intra-weekly variability in reported data was mitigated by using aggregated weekly data. R               t               estimated on weekly sliding windows using incidence reconstructed from weekly data was strongly correlated with estimates from the original daily data. The simulation study revealed that R               t               was well estimated in all scenarios and regardless of the temporal aggregation of the data. In the presence of weekend effects, R               t               estimates from reconstructed data were more successful at recovering the true value of R               t               than those obtained from reported daily data. These results show that this novel method allows R               t               to be successfully recovered from aggregated data using a simple approach with very few data requirements. Additionally, by removing administrative noise when daily incidence data are reconstructed, the accuracy of R               t               estimates can be improved.},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/V2UMKUHW/Nash et al. - 2023 - Estimating the epidemic reproduction number from t.pdf}
}

@article{nashRealtimeEstimationEpidemic2022,
  title = {Real-Time Estimation of the Epidemic Reproduction Number: {{Scoping}} Review of the Applications and Challenges},
  shorttitle = {Real-Time Estimation of the Epidemic Reproduction Number},
  author = {Nash, Rebecca K. and Nouvellet, Pierre and Cori, Anne},
  editor = {Tizzoni, Michele},
  year = {2022},
  month = jun,
  journal = {PLOS Digital Health},
  volume = {1},
  number = {6},
  pages = {e0000052},
  issn = {2767-3170},
  doi = {10.1371/journal.pdig.0000052},
  urldate = {2023-09-29},
  abstract = {The time-varying reproduction number (R               t               ) is an important measure of transmissibility during outbreaks. Estimating whether and how rapidly an outbreak is growing (R               t               {$>$} 1) or declining (R               t               {$<$} 1) can inform the design, monitoring and adjustment of control measures in real-time. We use a popular R package for R               t               estimation, EpiEstim, as a case study to evaluate the contexts in which R               t               estimation methods have been used and identify unmet needs which would enable broader applicability of these methods in real-time. A scoping review, complemented by a small EpiEstim user survey, highlight issues with the current approaches, including the quality of input incidence data, the inability to account for geographical factors, and other methodological issues. We summarise the methods and software developed to tackle the problems identified, but conclude that significant gaps remain which should be addressed to enable easier, more robust and applicable estimation of R               t               during epidemics.},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/Y9Y88SYT/Nash et al. - 2022 - Real-time estimation of the epidemic reproduction .pdf}
}

@article{nouvelletSimpleApproachMeasure2018,
  title = {A Simple Approach to Measure Transmissibility and Forecast Incidence},
  author = {Nouvellet, Pierre and Cori, Anne and Garske, Tini and Blake, Isobel M. and Dorigatti, Ilaria and Hinsley, Wes and Jombart, Thibaut and Mills, Harriet L. and {Nedjati-Gilani}, Gemma and Van Kerkhove, Maria D. and Fraser, Christophe and Donnelly, Christl A. and Ferguson, Neil M. and Riley, Steven},
  year = {2018},
  month = mar,
  journal = {Epidemics},
  series = {The {{RAPIDD Ebola Forecasting Challenge}}},
  volume = {22},
  pages = {29--35},
  issn = {1755-4365},
  doi = {10.1016/j.epidem.2017.02.012},
  urldate = {2024-10-27},
  abstract = {Outbreaks of novel pathogens such as SARS, pandemic influenza and Ebola require substantial investments in reactive interventions, with consequent implementation plans sometimes revised on a weekly basis. Therefore, short-term forecasts of incidence are often of high priority. In light of the recent Ebola epidemic in West Africa, a forecasting exercise was convened by a network of infectious disease modellers. The challenge was to forecast unseen ``future'' simulated data for four different scenarios at five different time points. In a similar method to that used during the recent Ebola epidemic, we estimated current levels of transmissibility, over variable time-windows chosen in an ad hoc way. Current estimated transmissibility was then used to forecast near-future incidence. We performed well within the challenge and often produced accurate forecasts. A retrospective analysis showed that our subjective method for deciding on the window of time with which to estimate transmissibility often resulted in the optimal choice. However, when near-future trends deviated substantially from exponential patterns, the accuracy of our forecasts was reduced. This exercise highlights the urgent need for infectious disease modellers to develop more robust descriptions of processes -- other than the widespread depletion of susceptible individuals -- that produce non-exponential patterns of incidence.},
  keywords = {Branching process,Forecasting,MCMC,Rapid response,Renewal equation},
  file = {/Users/nicsteyn/Documents/Zotero/storage/UVXR25D4/Nouvellet et al. - 2018 - A simple approach to measure transmissibility and .pdf;/Users/nicsteyn/Documents/Zotero/storage/RNI6MGFM/S1755436517300245.html}
}

@article{ogi-gittinsEfficientSimulationbasedInference2024,
  title = {Efficient Simulation-Based Inference of the Time-Dependent Reproduction Number from Temporally Aggregated and under-Reported Disease Incidence Time Series Data},
  author = {{Ogi-Gittins}, I and Steyn, N and Polonsky, J and Hart, {\relax WS} and Keita, M and {Ahuka-Mundeke}, S and Hill, {\relax EM} and Thompson, {\relax RN}},
  year = {2024},
  journal = {Work in progress}
}

@techreport{ogi-gittinsSimulationbasedApproachEstimating2023,
  type = {Preprint},
  title = {A Simulation-Based Approach for Estimating the Time-Dependent Reproduction Number from Temporally Aggregated Disease Incidence Time Series Data},
  author = {{Ogi-Gittins}, I and Hart, Ws and Song, J and Nash, Rk and Polonsky, J and Cori, A and Hill, Em and Thompson, Rn},
  year = {2023},
  month = sep,
  institution = {Infectious Diseases (except HIV/AIDS)},
  doi = {10.1101/2023.09.13.23295471},
  urldate = {2023-09-29},
  abstract = {Abstract           Tracking pathogen transmissibility during infectious disease outbreaks is essential for assessing the effectiveness of public health measures and planning future control strategies. A key measure of transmissibility is the time-dependent reproduction number, which has been estimated in real-time during outbreaks of a range of pathogens from disease incidence time series data. While commonly used approaches for estimating the time-dependent reproduction number can be reliable when disease incidence is recorded frequently, such incidence data are often aggregated temporally (for example, numbers of cases may be reported weekly rather than daily). As we show, commonly used methods for estimating transmissibility can be unreliable when the timescale of transmission is shorter than the timescale of data recording. To address this, here we develop a simulation-based approach involving Approximate Bayesian Computation for estimating the time-dependent reproduction number from temporally aggregated disease incidence time series data. We first use a simulated dataset representative of a situation in which daily disease incidence data are unavailable and only weekly summary values are reported, demonstrating that our method provides accurate estimates of the time-dependent reproduction number under those circumstances. We then apply our method to two previous outbreak datasets consisting of weekly influenza case numbers from 2019-20 and 2022-23 in Wales (in the United Kingdom). Our simple-to-use approach allows more accurate estimates of time-dependent reproduction numbers to be obtained during future infectious disease outbreaks.},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/Z6SL6ZS8/Ogi-Gittins et al. - 2023 - A simulation-based approach for estimating the tim.pdf}
}

@article{ogi-gittinsSimulationbasedApproachEstimating2024,
  title = {A Simulation-Based Approach for Estimating the Time-Dependent Reproduction Number from Temporally Aggregated Disease Incidence Time Series Data},
  author = {{Ogi-Gittins}, I. and Hart, W. S. and Song, J. and Nash, R. K. and Polonsky, J. and Cori, A. and Hill, E. M. and Thompson, R. N.},
  year = {2024},
  journal = {Epidemics},
  volume = {47},
  pages = {100773},
  issn = {1755-4365},
  doi = {10.1016/j.epidem.2024.100773},
  urldate = {2024-09-24},
  abstract = {Tracking pathogen transmissibility during infectious disease outbreaks is essential for assessing the effectiveness of public health measures and planning future control strategies. A key measure of transmissibility is the time-dependent reproduction number, which has been estimated in real-time during outbreaks of a range of pathogens from disease incidence time series data. While commonly used approaches for estimating the time-dependent reproduction number can be reliable when disease incidence is recorded frequently, such incidence data are often aggregated temporally (for example, numbers of cases may be reported weekly rather than daily). As we show, commonly used methods for estimating transmissibility can be unreliable when the timescale of transmission is shorter than the timescale of data recording. To address this, here we develop a simulation-based approach involving Approximate Bayesian Computation for estimating the time-dependent reproduction number from temporally aggregated disease incidence time series data. We first use a simulated dataset representative of a situation in which daily disease incidence data are unavailable and only weekly summary values are reported, demonstrating that our method provides accurate estimates of the time-dependent reproduction number under such circumstances. We then apply our method to two outbreak datasets consisting of weekly influenza case numbers in 2019--20 and 2022--23 in Wales (in the United Kingdom). Our simple-to-use approach will allow accurate estimates of time-dependent reproduction numbers to be obtained from temporally aggregated data during future infectious disease outbreaks.},
  keywords = {Approximate Bayesian Computation,Disease incidence,EpiEstim,Infectious disease epidemiology,Influenza,Mathematical modelling,Parameter inference,Reproduction number,Serial interval},
  file = {/Users/nicsteyn/Documents/Zotero/storage/662JLSKL/Ogi-Gittins et al. - 2024 - A simulation-based approach for estimating the tim.pdf;/Users/nicsteyn/Documents/Zotero/storage/BALI5FSP/S1755436524000343.html}
}

@article{paragAngularReproductionNumbers2023,
  title = {Angular Reproduction Numbers Improve Estimates of Transmissibility When Disease Generation Times Are Misspecified or Time-Varying},
  author = {Parag, Kris V. and Cowling, Benjamin J. and Lambert, Ben C.},
  year = {2023},
  month = sep,
  journal = {Proceedings of the Royal Society B: Biological Sciences},
  volume = {290},
  number = {2007},
  pages = {20231664},
  publisher = {Royal Society},
  doi = {10.1098/rspb.2023.1664},
  urldate = {2024-12-13},
  abstract = {We introduce the angular reproduction number {\textohm}, which measures time-varying changes in epidemic transmissibility resulting from variations in both the effective reproduction number R, and generation time distribution w. Predominant approaches for tracking pathogen spread infer either R or the epidemic growth rate r. However, R is biased by mismatches between the assumed and true w, while r is difficult to interpret in terms of the individual-level branching process underpinning transmission. R and r may also disagree on the relative transmissibility of epidemics or variants (i.e. rA {$>$} rB does not imply RA {$>$} RB for variants A and B). We find that {\textohm} responds meaningfully to mismatches and time-variations in w while mostly maintaining the interpretability of R. We prove that {\textohm} {$>$} 1 implies R {$>$} 1 and that {\textohm} agrees with r on the relative transmissibility of pathogens. Estimating {\textohm} is no more difficult than inferring R, uses existing software, and requires no generation time measurements. These advantages come at the expense of selecting one free parameter. We propose {\textohm} as complementary statistic to R and r that improves transmissibility estimates when w is misspecified or time-varying and better reflects the impact of interventions, when those interventions concurrently change R and w or alter the relative risk of co-circulating pathogens.},
  keywords = {epidemic models,generation times,growth rates,infectious diseases,reproduction numbers,transmission dynamics},
  file = {/Users/nicsteyn/Documents/Zotero/storage/4QXX24AI/Parag et al. - 2023 - Angular reproduction numbers improve estimates of .pdf}
}

@article{paragDecipheringEarlywarningSignals2021,
  title = {Deciphering Early-Warning Signals of {{SARS-CoV-2}} Elimination and Resurgence from Limited Data at Multiple Scales},
  author = {Parag, Kris V. and Cowling, Benjamin J. and Donnelly, Christl A.},
  year = {2021},
  month = dec,
  journal = {Journal of The Royal Society Interface},
  volume = {18},
  number = {185},
  pages = {20210569},
  issn = {1742-5662},
  doi = {10.1098/rsif.2021.0569},
  urldate = {2024-10-03},
  abstract = {Inferring the transmission potential of an infectious disease during low-incidence periods following epidemic waves is crucial for preparedness. In such periods, scarce data may hinder existing inference methods, blurring early-warning signals essential for discriminating between the likelihoods of resurgence versus elimination. Advanced insight into whether elevating caseloads (requiring swift community-wide interventions) or local elimination (allowing controls to be relaxed or refocussed on case-importation) might occur can separate decisive from ineffective policy. By generalizing and fusing recent approaches, we propose a novel early-warning framework that maximizes the information extracted from low-incidence data to robustly infer the chances of sustained local transmission or elimination in real time, at any scale of investigation (assuming sufficiently good surveillance). Applying this framework, we decipher hidden disease-transmission signals in prolonged low-incidence COVID-19 data from New Zealand, Hong Kong and Victoria, Australia. We uncover how timely interventions associate with averting resurgent waves, support official elimination declarations and evidence the effectiveness of the rapid, adaptive COVID-19 responses employed in these regions.},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/QIB2KGYF/Parag et al. - 2021 - Deciphering early-warning signals of SARS-CoV-2 el.pdf}
}

@article{paragImprovedEstimationTimevarying2021,
  title = {Improved Estimation of Time-Varying Reproduction Numbers at Low Case Incidence and between Epidemic Waves},
  author = {Parag, Kris V.},
  year = {2021},
  month = sep,
  journal = {PLOS Computational Biology},
  volume = {17},
  number = {9},
  pages = {e1009347},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1009347},
  urldate = {2023-09-10},
  abstract = {We construct a recursive Bayesian smoother, termed EpiFilter, for estimating the effective reproduction number, R, from the incidence of an infectious disease in real time and retrospectively. Our approach borrows from Kalman filtering theory, is quick and easy to compute, generalisable, deterministic and unlike many current methods, requires no change-point or window size assumptions. We model R as a flexible, hidden Markov state process and exactly solve forward-backward algorithms, to derive R estimates that incorporate all available incidence information. This unifies and extends two popular methods, EpiEstim, which considers past incidence, and the Wallinga-Teunis method, which looks forward in time. We find that this combination of maximising information and minimising assumptions significantly reduces the bias and variance of R estimates. Moreover, these properties make EpiFilter more statistically robust in periods of low incidence, where several existing methods can become destabilised. As a result, EpiFilter offers improved inference of time-varying transmission patterns that are advantageous for assessing the risk of upcoming waves of infection or the influence of interventions, in real time and at various spatial scales.},
  langid = {english},
  keywords = {COVID 19,Epidemiological statistics,Epidemiology,H1N1,Infectious disease control,Infectious disease epidemiology,New Zealand,notion,Pandemics},
  file = {/Users/nicsteyn/Documents/Zotero/storage/6V7EU3QM/Parag - 2021 - Improved estimation of time-varying reproduction n.pdf}
}

@article{paragQuantifyingInformationNoisy2022,
  title = {Quantifying the Information in Noisy Epidemic Curves},
  author = {Parag, Kris V. and Donnelly, Christl A. and Zarebski, Alexander E.},
  year = {2022},
  month = sep,
  journal = {Nature Computational Science},
  volume = {2},
  number = {9},
  pages = {584--594},
  issn = {2662-8457},
  doi = {10.1038/s43588-022-00313-1},
  urldate = {2023-09-10},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/Y326YJ3K/Parag et al. - 2022 - Quantifying the information in noisy epidemic curv.pdf}
}

@article{pittFilteringSimulationAuxiliary1999,
  title = {Filtering via {{Simulation}}: {{Auxiliary Particle Filters}}},
  shorttitle = {Filtering via {{Simulation}}},
  author = {Pitt, Michael K. and Shephard, Neil},
  year = {1999},
  journal = {Journal of the American Statistical Association},
  volume = {94},
  number = {446},
  eprint = {2670179},
  eprinttype = {jstor},
  pages = {590--599},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  issn = {0162-1459},
  doi = {10.2307/2670179},
  urldate = {2024-10-25},
  abstract = {This article analyses the recently suggested particle approach to filtering time series. We suggest that the algorithm is not robust to outliers for two reasons: the design of the simulators and the use of the discrete support to represent the sequentially updating prior distribution. Here we tackle the first of these problems.},
  file = {/Users/nicsteyn/Documents/Zotero/storage/P2XK97HH/Pitt and Shephard - 1999 - Filtering via Simulation Auxiliary Particle Filte.pdf}
}

@article{plankEstimationEndofoutbreakProbabilities2025,
  title = {Estimation of End-of-Outbreak Probabilities in the Presence of Delayed and Incomplete Case Reporting},
  author = {Plank, M. J. and Hart, W. S. and Polonsky, J. and Keita, M. and {Ahuka-Mundeke}, S. and Thompson, R. N.},
  year = {2025},
  month = jan,
  journal = {Proceedings of the Royal Society B: Biological Sciences},
  volume = {292},
  number = {2039},
  pages = {20242825},
  publisher = {Royal Society},
  doi = {10.1098/rspb.2024.2825},
  urldate = {2025-01-30},
  abstract = {Towards the end of an infectious disease outbreak, when a period has elapsed without new case notifications, a key question for public health policymakers is whether the outbreak can be declared over. This requires the benefits of a declaration (e.g. relaxation of outbreak control measures) to be balanced against the risk of a resurgence in cases. To support this decision-making, mathematical methods have been developed to quantify the end-of-outbreak probability. Here, we propose a new approach to this problem that accounts for a range of features of real-world outbreaks, specifically: (i) incomplete case ascertainment, (ii) reporting delays, (iii) individual heterogeneity in transmissibility and (iv) whether cases were imported or infected locally. We showcase our approach using two case studies: Covid-19 in New Zealand in 2020 and Ebola virus disease in the Democratic Republic of the Congo in 2018. In these examples, we found that the date when the estimated probability of no future infections reached 95\% was relatively consistent across a range of modelling assumptions. This suggests that our modelling framework can generate robust quantitative estimates that can be used by policy advisors, alongside other sources of evidence, to inform end-of-outbreak declarations.},
  keywords = {disease elimination,infectious diseases,mathematical modelling,stochastic model},
  file = {/Users/nicsteyn/Documents/Zotero/storage/KZD52KH2/Plank et al. - 2025 - Estimation of end-of-outbreak probabilities in the.pdf}
}

@misc{rimellaApproximatingOptimalSMC2023,
  title = {Approximating Optimal {{SMC}} Proposal Distributions in Individual-Based Epidemic Models},
  author = {Rimella, Lorenzo and Jewell, Christopher and Fearnhead, Paul},
  year = {2023},
  month = mar,
  number = {arXiv:2206.05161},
  eprint = {2206.05161},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2206.05161},
  urldate = {2024-10-03},
  abstract = {Many epidemic models are naturally defined as individual-based models: where we track the state of each individual within a susceptible population. Inference for individual-based models is challenging due to the high-dimensional state-space of such models, which increases exponentially with population size. We consider sequential Monte Carlo algorithms for inference for individual-based epidemic models where we make direct observations of the state of a sample of individuals. Standard implementations, such as the bootstrap filter or the auxiliary particle filter are inefficient due to mismatch between the proposal distribution of the state and future observations. We develop new efficient proposal distributions that take account of future observations, leveraging the properties that (i) we can analytically calculate the optimal proposal distribution for a single individual given future observations and the future infection rate of that individual; and (ii) the dynamics of individuals are independent if we condition on their infection rates. Thus we construct estimates of the future infection rate for each individual, and then use an independent proposal for the state of each individual given this estimate. Empirical results show order of magnitude improvement in efficiency of the sequential Monte Carlo sampler for both SIS and SEIR models.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Methodology},
  file = {/Users/nicsteyn/Documents/Zotero/storage/72QF49FL/Rimella et al. - 2023 - Approximating optimal SMC proposal distributions i.pdf;/Users/nicsteyn/Documents/Zotero/storage/HEPY3NR5/2206.html}
}

@book{robertBayesianChoiceDecisionTheoretic2007,
  title = {The {{Bayesian Choice}}: {{From Decision-Theoretic Foundations}} to {{Computational Implementation}}},
  shorttitle = {The {{Bayesian Choice}}},
  editor = {Robert, Christian P.},
  year = {2007},
  series = {Springer {{Texts}} in {{Statistics}}},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/0-387-71599-1},
  isbn = {978-0-387-71598-8 978-0-387-71599-5},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/HXGF7SKL/Robert - 2007 - The Bayesian Choice From Decision-Theoretic Found.pdf}
}

@article{robertsEarlyEstimationReproduction2011,
  title = {Early {{Estimation}} of the {{Reproduction Number}} in the {{Presence}} of {{Imported Cases}}: {{Pandemic Influenza H1N1-2009}} in {{New Zealand}}},
  shorttitle = {Early {{Estimation}} of the {{Reproduction Number}} in the {{Presence}} of {{Imported Cases}}},
  author = {Roberts, Michael George and Nishiura, Hiroshi},
  year = {2011},
  month = may,
  journal = {PLOS ONE},
  volume = {6},
  number = {5},
  pages = {e17835},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0017835},
  urldate = {2025-03-10},
  abstract = {We analyse data from the early epidemic of H1N1-2009 in New Zealand, and estimate the reproduction number . We employ a renewal process which accounts for imported cases, illustrate some technical pitfalls, and propose a novel estimation method to address these pitfalls. Explicitly accounting for the infection-age distribution of imported cases and for the delay in transmission dynamics due to international travel, was estimated to be (95\% confidence interval: ). Hence we show that a previous study, which did not account for these factors, overestimated . Our approach also permitted us to examine the infection-age at which secondary transmission occurs as a function of calendar time, demonstrating the downward bias during the beginning of the epidemic. These technical issues may compromise the usefulness of a well-known estimator of - the inverse of the moment-generating function of the generation time given the intrinsic growth rate. Explicit modelling of the infection-age distribution among imported cases and the examination of the time dependency of the generation time play key roles in avoiding a biased estimate of , especially when one only has data covering a short time interval during the early growth phase of the epidemic.},
  langid = {english},
  keywords = {Entropy,Epidemiology,Infectious disease epidemiology,Influenza,Mexico,New Zealand,Pandemics,Statistical distributions},
  file = {/Users/nicsteyn/Documents/Zotero/storage/9VD5CS44/Roberts and Nishiura - 2011 - Early Estimation of the Reproduction Number in the.pdf}
}

@article{rubinInferenceMissingData1976,
  title = {Inference and Missing Data},
  author = {Rubin, Donald B.},
  year = {1976},
  month = dec,
  journal = {Biometrika},
  volume = {63},
  number = {3},
  pages = {581--592},
  issn = {0006-3444},
  doi = {10.1093/biomet/63.3.581},
  urldate = {2025-03-03},
  abstract = {When making sampling distribution inferences about the parameter of the data, {\texttheta}, it is appropriate to ignore the process that causes missing data if the missing data are `missing at random' and the observed data are `observed at random', but these inferences are generally conditional on the observed pattern of missing data. When making direct-likelihood or Bayesian inferences about {\texttheta}, it is appropriate to ignore the process that causes missing data if the missing data are missing at random and the parameter of the missing data process is `distinct' from {\texttheta}. These conditions are the weakest general conditions under which ignoring the process that causes missing data always leads to correct inferences.},
  file = {/Users/nicsteyn/Documents/Zotero/storage/F8GIPUVL/RUBIN - 1976 - Inference and missing data.pdf;/Users/nicsteyn/Documents/Zotero/storage/SEGSSPEK/270932.html}
}

@article{safarishahrbijariPredictiveAccuracyParticle2017,
  title = {Predictive Accuracy of Particle Filtering in Dynamic Models Supporting Outbreak Projections},
  author = {Safarishahrbijari, Anahita and Teyhouee, Aydin and Waldner, Cheryl and Liu, Juxin and Osgood, Nathaniel D.},
  year = {2017},
  month = sep,
  journal = {BMC Infectious Diseases},
  volume = {17},
  number = {1},
  pages = {648},
  issn = {1471-2334},
  doi = {10.1186/s12879-017-2726-9},
  urldate = {2024-09-02},
  abstract = {While a new generation of computational statistics algorithms and availability of data streams raises the potential for recurrently regrounding dynamic models with incoming observations, the effectiveness of such arrangements can be highly subject to specifics of the configuration (e.g., frequency of sampling and representation of behaviour change), and there has been little attempt to identify effective configurations.},
  langid = {english},
  keywords = {Communicable illness,Compartmental model,Empirical observations,Infectious diseases,Outbreaks,Particle filtering,Stochastic,System dynamics,Transmission model},
  file = {/Users/nicsteyn/Documents/Zotero/storage/HTA777V8/Safarishahrbijari et al. - 2017 - Predictive accuracy of particle filtering in dynam.pdf}
}

@book{sarkkaBayesianFilteringSmoothing2013,
  title = {Bayesian {{Filtering}} and {{Smoothing}}},
  author = {S{\"a}rkk{\"a}, Simo},
  year = {2013},
  month = sep,
  edition = {1},
  publisher = {Cambridge University Press},
  doi = {10.1017/CBO9781139344203},
  urldate = {2023-09-13},
  abstract = {Filtering and smoothing methods are used to produce an accurate estimate of the state of a time-varying system based on multiple observational inputs (data). Interest in these methods has exploded in recent years, with numerous applications emerging in fields such as navigation, aerospace engineering, telecommunications and medicine. This compact, informal introduction for graduate students and advanced undergraduates presents the current state-of-the-art filtering and smoothing methods in a unified Bayesian framework. Readers learn what non-linear Kalman filters and particle filters are, how they are related, and their relative advantages and disadvantages. They also discover how state-of-the-art Bayesian parameter estimation methods can be combined with state-of-the-art filtering and smoothing algorithms. The book's practical and algorithmic approach assumes only modest mathematical prerequisites. Examples include Matlab computations, and the numerous end-of-chapter exercises include computational assignments. Matlab code is available for download at www.cambridge.org/sarkka, promoting hands-on work with the methods.},
  isbn = {978-1-107-03065-7 978-1-139-34420-3 978-1-107-61928-9},
  keywords = {notion}
}

@misc{scottEpidemiaModelingEpidemics,
  title = {Epidemia: {{Modeling}} of {{Epidemics}} Using {{Hierarchical Bayesian Models}}},
  author = {Scott, James A and Gandy, Axel and Mishra, Swapnil and Unwin, Juliette and Flaxman, Seth and Bhatt, Samir}
}

@article{sheinsonComparisonPerformanceParticle2014,
  title = {Comparison of the Performance of Particle Filter Algorithms Applied to Tracking of a Disease Epidemic},
  author = {Sheinson, Daniel M. and Niemi, Jarad and Meiring, Wendy},
  year = {2014},
  month = sep,
  journal = {Mathematical Biosciences},
  volume = {255},
  pages = {21--32},
  issn = {0025-5564},
  doi = {10.1016/j.mbs.2014.06.018},
  urldate = {2024-10-03},
  abstract = {We present general methodology for sequential inference in nonlinear stochastic state-space models to simultaneously estimate dynamic states and fixed parameters. We show that basic particle filters may fail due to degeneracy in fixed parameter estimation and suggest the use of a kernel density approximation to the filtered distribution of the fixed parameters to allow the fixed parameters to regenerate. In addition, we show that ``seemingly'' uninformative uniform priors on fixed parameters can affect posterior inferences and suggest the use of priors bounded only by the support of the parameter. We show the negative impact of using multinomial resampling and suggest the use of either stratified or residual resampling within the particle filter. As a motivating example, we use a model for tracking and prediction of a disease outbreak via a syndromic surveillance system. Finally, we use this improved particle filtering methodology to relax prior assumptions on model parameters yet still provide reasonable estimates for model parameters and disease states.},
  keywords = {Bayesian estimation,Epidemiological modeling,Particle filtering,Sequential Monte Carlo,State-space modeling},
  file = {/Users/nicsteyn/Documents/Zotero/storage/VN8P5SPB/S0025556414001242.html}
}

@article{sherrattExploringSurveillanceData2021,
  title = {Exploring Surveillance Data Biases When Estimating the Reproduction Number: With Insights into Subpopulation Transmission of {{COVID-19}} in {{England}}},
  shorttitle = {Exploring Surveillance Data Biases When Estimating the Reproduction Number},
  author = {Sherratt, Katharine and Abbott, Sam and Meakin, Sophie R. and Hellewell, Joel and Munday, James D. and Bosse, Nikos and {null}, null and Jit, Mark and Funk, Sebastian},
  year = {2021},
  month = may,
  journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
  volume = {376},
  number = {1829},
  pages = {20200283},
  publisher = {Royal Society},
  doi = {10.1098/rstb.2020.0283},
  urldate = {2024-10-27},
  abstract = {The time-varying reproduction number (Rt: the average number of secondary infections caused by each infected person) may be used to assess changes in transmission potential during an epidemic. While new infections are not usually observed directly, they can be estimated from data. However, data may be delayed and potentially biased. We investigated the sensitivity of Rt estimates to different data sources representing COVID-19 in England, and we explored how this sensitivity could track epidemic dynamics in population sub-groups. We sourced public data on test-positive cases, hospital admissions and deaths with confirmed COVID-19 in seven regions of England over March through August 2020. We estimated Rt using a model that mapped unobserved infections to each data source. We then compared differences in Rt with the demographic and social context of surveillance data over time. Our estimates of transmission potential varied for each data source, with the relative inconsistency of estimates varying across regions and over time. Rt estimates based on hospital admissions and deaths were more spatio-temporally synchronous than when compared to estimates from all test positives. We found these differences may be linked to biased representations of subpopulations in each data source. These included spatially clustered testing, and where outbreaks in hospitals, care homes, and young age groups reflected the link between age and severity of the disease. We highlight that policy makers could better target interventions by considering the source populations of Rt estimates. Further work should clarify the best way to combine and interpret Rt estimates from different data sources based on the desired use. This article is part of the theme issue `Modelling that shaped the early COVID-19 pandemic response in the UK'.},
  keywords = {bias,COVID-19,SARS-CoV-2,surveillance,time-varying reproduction number,transmission},
  file = {/Users/nicsteyn/Documents/Zotero/storage/DG9XE6F2/Sherratt et al. - 2021 - Exploring surveillance data biases when estimating.pdf}
}

@article{spannausInferringSpreadCOVID192022,
  title = {Inferring the Spread of {{COVID-19}}: The Role of Time-Varying Reporting Rate in Epidemiological Modelling},
  shorttitle = {Inferring the Spread of {{COVID-19}}},
  author = {Spannaus, Adam and Papamarkou, Theodore and Erwin, Samantha and Christian, J. Blair},
  year = {2022},
  month = jun,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {10761},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-14979-0},
  urldate = {2024-10-03},
  abstract = {The role of epidemiological models is crucial for informing public health officials during a public health emergency, such as the COVID-19 pandemic. However, traditional epidemiological models fail to capture the time-varying effects of mitigation strategies and do not account for under-reporting of active cases, thus introducing bias in the estimation of model parameters. To infer more accurate parameter estimates and to reduce the uncertainty of these estimates, we extend the SIR and SEIR epidemiological models with two time-varying parameters that capture the transmission rate and the rate at which active cases are reported to health officials. Using two real data sets of COVID-19 cases, we perform Bayesian inference via our SIR and SEIR models with time-varying transmission and reporting rates and via their standard counterparts with constant rates; our approach provides parameter estimates with more realistic interpretation, and 1-week ahead predictions with reduced uncertainty. Furthermore, we find consistent under-reporting in the number of active cases in the data that we consider, suggesting that the initial phase of the pandemic was more widespread than previously reported.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Applied mathematics,Computational models},
  file = {/Users/nicsteyn/Documents/Zotero/storage/SN66PS93/Spannaus et al. - 2022 - Inferring the spread of COVID-19 the role of time.pdf}
}

@misc{standevelopmentteamStanReferenceManual2024,
  title = {Stan {{Reference Manual}}},
  author = {\{Stan Development Team\}},
  year = {2024},
  month = dec
}

@misc{steynRobustUncertaintyQuantification2024,
  title = {Robust Uncertainty Quantification in Popular Estimators of the Instantaneous Reproduction Number},
  author = {Steyn, Nicholas and Parag, Kris V.},
  year = {2024},
  month = oct,
  pages = {2024.10.22.24315918},
  publisher = {medRxiv},
  doi = {10.1101/2024.10.22.24315918},
  urldate = {2024-10-25},
  abstract = {The instantaneous reproduction number (Rt) is a widely used measure of the rate of spread of an infectious disease. Correct quantification of the uncertainty of Rt estimates is crucial for making well-informed decisions. Popular methods for estimating Rt leverage smoothing techniques to distinguish signal from noise. Examples include EpiEstim and EpiFilter, each are controlled by a single "smoothing parameter", which is traditionally chosen by the user. We demonstrate that the values of these smoothing parameters are unknown and vary markedly with epidemic dynamics. We argue that data-driven smoothing choices are crucial for accurately representing uncertainty about Rt estimates. We derive model likelihoods for the smoothing parameters in both EpiEstim and EpiFilter. Adopting a flexible Bayesian framework, we use these likelihoods to automatically marginalise out the relevant smoothing parameters from these models when fitting to incidence time-series. Applying our methods, we find that the default parameterisations of these models can negatively impact inferences of Rt, delaying detection of epidemic growth, and misrepresenting uncertainty (typically by producing overconfident estimates), with substantial implications for public health decision-making. Our extensions mitigate these issues, provide a principled approach to uncertainty quantification, and improve the robustness of inference of Rt in real-time.},
  archiveprefix = {medRxiv},
  copyright = {{\copyright} 2024, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
  langid = {english},
  file = {/Users/nicsteyn/Documents/Zotero/storage/TBDPPTNZ/Steyn and Parag - 2024 - Robust uncertainty quantification in popular estim.pdf}
}

@article{storvikSequentialMonteCarlo2023,
  title = {A Sequential {{Monte Carlo}} Approach to Estimate a Time-Varying Reproduction Number in Infectious Disease Models: The {{Covid-19}} Case*},
  shorttitle = {A Sequential {{Monte Carlo}} Approach to Estimate a Time-Varying Reproduction Number in Infectious Disease Models},
  author = {Storvik, Geir and {Diz-Lois Palomares}, Alfonso and Engebretsen, Solveig and R{\o}, Gunnar {\O}yvind Isaksson and {Eng{\o}-Monsen}, Kenth and Kristoffersen, Anja Br{\aa}then and {de Blasio}, Birgitte Freiesleben and Frigessi, Arnoldo},
  year = {2023},
  month = oct,
  journal = {Journal of the Royal Statistical Society Series A: Statistics in Society},
  volume = {186},
  number = {4},
  pages = {616--632},
  issn = {0964-1998},
  doi = {10.1093/jrsssa/qnad043},
  urldate = {2024-10-03},
  abstract = {The Covid-19 pandemic has required most countries to implement complex sequences of non-pharmaceutical interventions, with the aim of controlling the transmission of the virus in the population. To be able to take rapid decisions, a detailed understanding of the current situation is necessary. Estimates of time-varying, instantaneous reproduction numbers represent a way to quantify the viral transmission in real time. They are often defined through a mathematical compartmental model of the epidemic, like a stochastic SEIR model, whose parameters must be estimated from multiple time series of epidemiological data. Because of very high dimensional parameter spaces (partly due to the stochasticity in the spread models) and incomplete and delayed data, inference is very challenging. We propose a state-space formalization of the model and a sequential Monte Carlo approach which allow to estimate a daily-varying reproduction number for the Covid-19 epidemic in Norway with sufficient precision, on the basis of daily hospitalization and positive test incidences. The method was in regular use in Norway during the pandemics and appears to be a powerful instrument for epidemic monitoring and management.},
  file = {/Users/nicsteyn/Documents/Zotero/storage/GXCDFD96/Storvik et al. - 2023 - A sequential Monte Carlo approach to estimate a ti.pdf;/Users/nicsteyn/Documents/Zotero/storage/MRC3FCJH/7145945.html}
}

@misc{temfackReviewSequentialMonte2024b,
  title = {A Review of Sequential {{Monte Carlo}} Methods for Real-Time Disease Modeling},
  author = {Temfack, Dhorasso and Wyse, Jason},
  year = {2024},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2408.15739},
  urldate = {2024-10-03},
  abstract = {Sequential Monte Carlo methods are a powerful framework for approximating the posterior distribution of a state variable in a sequential manner. They provide an attractive way of analyzing dynamic systems in real-time, taking into account the limitations of traditional approaches such as Markov Chain Monte Carlo methods, which are not well suited to data that arrives incrementally. This paper reviews and explores the application of Sequential Monte Carlo in dynamic disease modeling, highlighting its capacity for online inference and real-time adaptation to evolving disease dynamics. The integration of kernel density approximation techniques within the stochastic Susceptible-Exposed-Infectious-Recovered (SEIR) compartment model is examined, demonstrating the algorithm's effectiveness in monitoring time-varying parameters such as the effective reproduction number. Case studies, including simulations with synthetic data and analysis of real-world COVID-19 data from Ireland, demonstrate the practical applicability of this approach for informing timely public health interventions.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {Computation (stat.CO),Dynamical Systems (math.DS),FOS: Biological sciences,FOS: Computer and information sciences,FOS: Mathematics,Populations and Evolution (q-bio.PE)}
}

@article{thompsonImprovedInferenceTimevarying2019,
  title = {Improved Inference of Time-Varying Reproduction Numbers during Infectious Disease Outbreaks},
  author = {Thompson, R. N. and Stockwin, J. E. and {van Gaalen}, R. D. and Polonsky, J. A. and Kamvar, Z. N. and Demarsh, P. A. and Dahlqwist, E. and Li, S. and Miguel, E. and Jombart, T. and Lessler, J. and Cauchemez, S. and Cori, A.},
  year = {2019},
  month = dec,
  journal = {Epidemics},
  volume = {29},
  pages = {100356},
  issn = {1755-4365},
  doi = {10.1016/j.epidem.2019.100356},
  urldate = {2023-09-09},
  abstract = {Accurate estimation of the parameters characterising infectious disease transmission is vital for optimising control interventions during epidemics. A valuable metric for assessing the current threat posed by an outbreak is the time-dependent reproduction number, i.e. the expected number of secondary cases caused by each infected individual. This quantity can be estimated using data on the numbers of observed new cases at successive times during an epidemic and the distribution of the serial interval (the time between symptomatic cases in a transmission chain). Some methods for estimating the reproduction number rely on pre-existing estimates of the serial interval distribution and assume that the entire outbreak is driven by local transmission. Here we show that accurate inference of current transmissibility, and the uncertainty associated with this estimate, requires: (i) up-to-date observations of the serial interval to be included, and; (ii) cases arising from local transmission to be distinguished from those imported from elsewhere. We demonstrate how pathogen transmissibility can be inferred appropriately using datasets from outbreaks of H1N1 influenza, Ebola virus disease and Middle-East Respiratory Syndrome. We present a tool for estimating the reproduction number in real-time during infectious disease outbreaks accurately, which is available as an R software package (EpiEstim 2.2). It is also accessible as an interactive, user-friendly online interface (EpiEstim App), permitting its use by non-specialists. Our tool is easy to apply for assessing the transmission potential, and hence informing control, during future outbreaks of a wide range of invading pathogens.},
  keywords = {Disease control,Infectious disease epidemiology,Mathematical modelling,Parameter inference,Reproduction number,Serial interval},
  file = {/Users/nicsteyn/Documents/Zotero/storage/5T2BIEFS/Thompson et al. - 2019 - Improved inference of time-varying reproduction nu.pdf;/Users/nicsteyn/Documents/Zotero/storage/D25GFUVV/S1755436519300350.html}
}

@article{thompsonUsingRealtimeModelling2024,
  title = {Using Real-Time Modelling to Inform the 2017 {{Ebola}} Outbreak Response in {{DR Congo}}},
  author = {Thompson, R. and Hart, W. and Keita, M. and Fall, I. and Gueye, A. and Chamla, D. and Mossoko, M. and {Ahuka-Mundeke}, S. and {Nsio-Mbeta}, J. and Jombart, T. and Polonsky, J.},
  year = {2024},
  month = jul,
  journal = {Nature Communications},
  volume = {15},
  number = {1},
  pages = {5667},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-024-49888-5},
  urldate = {2025-01-30},
  abstract = {Important policy questions during infections disease outbreaks include: i) How effective are particular interventions?; ii) When can resource-intensive interventions be removed? We used mathematical modelling to address these questions during the 2017 Ebola outbreak in Likati Health Zone, Democratic Republic of the Congo (DRC). Eight cases occurred before 15 May 2017, when the Ebola Response Team (ERT; co-ordinated by the World Health Organisation and DRC Ministry of Health) was deployed to reduce transmission. We used a branching process model to estimate that, pre-ERT arrival, the reproduction number was \$\$R=1.49\$\$(95\% credible interval \$\$(\{\{\{\{{\textbackslash}mathrm\{0.67,2.81\}\}\}\}\})\$\$). The risk of further cases occurring without the ERT was estimated to be 0.97 (97\%). However, no cases materialised, suggesting that the ERT's measures were effective. We also estimated the risk of withdrawing the ERT in real-time. By the actual ERT withdrawal date (2 July 2017), the risk of future cases without the ERT was only 0.01, indicating that the ERT withdrawal decision was safe. We evaluated the sensitivity of our results to the estimated \$\$R\$\$value and considered different criteria for determining the ERT withdrawal date. This research provides an extensible modelling framework that can be used to guide decisions about when to relax interventions during future outbreaks.},
  copyright = {2024 The Author(s)},
  langid = {english},
  keywords = {Computational models,Ebola virus,Ecological modelling,Epidemiology,Viral infection},
  file = {/Users/nicsteyn/Documents/Zotero/storage/WLP5QJVN/Thompson et al. - 2024 - Using real-time modelling to inform the 2017 Ebola.pdf}
}

@misc{UtilitiesScoringAssessing,
  title = {Utilities for {{Scoring}} and {{Assessing Predictions}}},
  urldate = {2024-09-15},
  abstract = {Provides a collection of metrics and proper scoring rules (Tilmann Gneiting \& Adrian E Raftery (2007) {$<$}doi:10.1198/016214506000001437{$>$}, Jordan, A., Kr{\"u}ger, F., \& Lerch, S. (2019) {$<$}doi:10.18637/jss.v090.i12{$>$}) within a consistent framework for evaluation, comparison and visualisation of forecasts. In addition to proper scoring rules, functions are provided to assess bias, sharpness and calibration (Sebastian Funk, Anton Camacho, Adam J. Kucharski, Rachel Lowe, Rosalind M. Eggo, W. John Edmunds (2019) {$<$}doi:10.1371/journal.pcbi.1006785{$>$}) of forecasts. Several types of predictions (e.g. binary, discrete, continuous) which may come in different formats (e.g. forecasts represented by predictive samples or by quantiles of the predictive distribution) can be evaluated. Scoring metrics can be used either through a convenient data.frame format, or can be applied as individual functions in a vector / matrix format. All functionality has been implemented with a focus on performance and is robustly tested. Find more information about the package in the accompanying paper ({$<$}doi:10.48550/arXiv.2205.07090{$>$}).},
  howpublished = {https://epiforecasts.io/scoringutils/index.html},
  langid = {english}
}

@article{watsonJointlyEstimatingEpidemiological2024,
  title = {Jointly Estimating Epidemiological Dynamics of {{Covid-19}} from Case and Wastewater Data in {{Aotearoa New Zealand}}},
  author = {Watson, Leighton M. and Plank, Michael J. and Armstrong, Bridget A. and Chapman, Joanne R. and Hewitt, Joanne and Morris, Helen and Orsi, Alvaro and Bunce, Michael and Donnelly, Christl A. and Steyn, Nicholas},
  year = {2024},
  month = jul,
  journal = {Communications Medicine},
  volume = {4},
  number = {1},
  pages = {1--9},
  publisher = {Nature Publishing Group},
  issn = {2730-664X},
  doi = {10.1038/s43856-024-00570-3},
  urldate = {2024-09-02},
  abstract = {Timely and informed public health responses to infectious diseases such as COVID-19 necessitate reliable information about infection dynamics. The case ascertainment rate (CAR), the proportion of infections that are reported as cases, is typically much less than one and varies with testing practices and behaviours, making reported cases unreliable as the sole source of data. The concentration of viral RNA in wastewater samples provides an alternate measure of infection prevalence that is not affected by clinical testing, healthcare-seeking behaviour or access to care.},
  copyright = {2024 The Author(s)},
  langid = {english},
  keywords = {Epidemiology,Infectious diseases,Viral infection},
  file = {/Users/nicsteyn/Documents/Zotero/storage/VW3VF737/Watson et al. - 2024 - Jointly estimating epidemiological dynamics of Cov.pdf}
}

@misc{weldingRealTimeAnalysis2019,
  title = {Real Time Analysis of Epidemic Data},
  author = {Welding, Jessica and Neal, Peter},
  year = {2019},
  month = sep,
  number = {arXiv:1909.11560},
  eprint = {1909.11560},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1909.11560},
  urldate = {2024-10-03},
  abstract = {Infectious diseases have severe health and economic consequences for society. It is important in controlling the spread of an emerging infectious disease to be able to both estimate the parameters of the underlying model and identify those individuals most at risk of infection in a timely manner. This requires having a mechanism to update inference on the model parameters and the progression of the disease as new data becomes available. However, Markov chain Monte Carlo (MCMC), the gold standard for statistical inference for infectious disease models, is not equipped to deal with this important problem. Motivated by the need to develop effective statistical tools for emerging diseases and using the 2001 UK Foot-and-Mouth disease outbreak as an exemplar, we introduce a Sequential Monte Carlo (SMC) algorithm to enable real-time analysis of epidemic outbreaks. Naive application of SMC methods leads to significant particle degeneracy which are successfully overcome by particle perturbation and incorporating MCMC-within-SMC updates.},
  archiveprefix = {arXiv},
  keywords = {Statistics - Applications,Statistics - Computation},
  file = {/Users/nicsteyn/Documents/Zotero/storage/KX7V9QXK/Welding and Neal - 2019 - Real time analysis of epidemic data.pdf;/Users/nicsteyn/Documents/Zotero/storage/Y8LF39Z7/1909.html}
}

@article{whiteReportingErrorsInfectious2010,
  title = {Reporting Errors in Infectious Disease Outbreaks, with an Application to {{Pandemic Influenza A}}/{{H1N1}}},
  author = {White, Laura F. and Pagano, Marcello},
  year = {2010},
  month = dec,
  journal = {Epidemiologic Perspectives \& Innovations},
  volume = {7},
  number = {1},
  pages = {12},
  issn = {1742-5573},
  doi = {10.1186/1742-5573-7-12},
  urldate = {2023-09-12},
  abstract = {Effectively responding to infectious disease outbreaks requires a well-informed response. Quantitative methods for analyzing outbreak data and estimating key parameters to characterize the spread of the outbreak, including the reproductive number and the serial interval, often assume that the data collected is complete. In reality reporting delays, undetected cases or lack of sensitive and specific tests to diagnose disease lead to reporting errors in the case counts. Here we provide insight on the impact that such reporting errors might have on the estimation of these key parameters.},
  file = {/Users/nicsteyn/Documents/Zotero/storage/64YD9IIY/White and Pagano - 2010 - Reporting errors in infectious disease outbreaks, .pdf;/Users/nicsteyn/Documents/Zotero/storage/BSWA28RE/1742-5573-7-12.html}
}

@article{wilderTrackingDiseaseOutbreaks2021,
  title = {Tracking {{Disease Outbreaks}} from {{Sparse Data}} with {{Bayesian Inference}}},
  author = {Wilder, Bryan and Mina, Michael and Tambe, Milind},
  year = {2021},
  month = may,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {35},
  number = {6},
  pages = {4883--4891},
  issn = {2374-3468},
  doi = {10.1609/aaai.v35i6.16621},
  urldate = {2024-10-27},
  abstract = {The COVID-19 pandemic provides new motivation for a classic problem in epidemiology: estimating the empirical rate of transmission during an outbreak (formally, the time-varying reproduction number) from case counts. While standard methods exist, they work best at coarse-grained national or state scales with abundant data, and struggle to accommodate the partial observability and sparse data common at finer scales (e.g., individual schools or towns). For example, case counts may be sparse when only a small fraction of infections are caught by a testing program. Or, whether an infected individual tests positive may depend on the kind of test and the point in time when they are tested. We propose a Bayesian framework which accommodates partial observability in a principled manner. Our model places a Gaussian process prior over the unknown reproduction number at each time step and models observations sampled from the distribution of a specific testing program. For example, our framework can accommodate a variety of kinds of tests (viral RNA, antibody, antigen, etc.) and sampling schemes (e.g., longitudinal or cross-sectional screening). Inference in this framework is complicated by the presence of tens or hundreds of thousands of discrete latent variables. To address this challenge, we propose an efficient stochastic variational inference method which relies on a novel gradient estimator for the variational objective. Experimental results for an example motivated by COVID-19 show that our method produces an accurate and well-calibrated posterior, while standard methods for estimating the reproduction number can fail badly.},
  copyright = {Copyright (c) 2021 Association for the Advancement of Artificial Intelligence},
  langid = {english},
  keywords = {AI Responses to the COVID-19 Pandemic (Covid19)},
  file = {/Users/nicsteyn/Documents/Zotero/storage/LLNMKCJ7/Wilder et al. - 2021 - Tracking Disease Outbreaks from Sparse Data with B.pdf}
}

@article{wonEstimatingInstantaneousReproduction2023,
  title = {Estimating the Instantaneous Reproduction Number ({{Rt}}) by Using Particle Filter},
  author = {Won, Yong Sul and Son, Woo-Sik and Choi, Sunhwa and Kim, Jong-Hoon},
  year = {2023},
  month = dec,
  journal = {Infectious Disease Modelling},
  volume = {8},
  number = {4},
  pages = {1002--1014},
  issn = {2468-0427},
  doi = {10.1016/j.idm.2023.08.003},
  urldate = {2024-09-02},
  abstract = {Background Monitoring the transmission of coronavirus disease 2019 (COVID-19) requires accurate estimation of the effective reproduction number (Rt). However, existing methods for calculating Rt may yield biased estimates if important real-world factors, such as delays in confirmation, pre-symptomatic transmissions, or imperfect data observation, are not considered. Method To include real-world factors, we expanded the susceptible-exposed-infectious-recovered (SEIR) model by incorporating pre-symptomatic (P) and asymptomatic (A) states, creating the SEPIAR model. By utilizing both stochastic and deterministic versions of the model, and incorporating predetermined time series of Rt, we generated simulated datasets that simulate real-world challenges in estimating Rt. We then compared the performance of our proposed particle filtering method for estimating Rt with the existing EpiEstim approach based on renewal equations. Results The particle filtering method accurately estimated Rt even in the presence of data with delays, pre-symptomatic transmission, and imperfect observation. When evaluating via the root mean square error (RMSE) metric, the performance of the particle filtering method was better in general and was comparable to the EpiEstim approach if perfectly deconvolved infection time series were provided, and substantially better when Rt exhibited short-term fluctuations and the data was right truncated. Conclusions The SEPIAR model, in conjunction with the particle filtering method, offers a reliable tool for predicting the transmission trend of COVID-19 and assessing the impact of intervention strategies. This approach enables enhanced monitoring of COVID-19 transmission and can inform public health policies aimed at controlling the spread of the disease.},
  keywords = {Compartment model,COVID-19,Effective reproduction number,Particle filter,Sequential Monte Carlo,Transmission model},
  file = {/Users/nicsteyn/Documents/Zotero/storage/QUVFJYSQ/Won et al. - 2023 - Estimating the instantaneous reproduction number (.pdf;/Users/nicsteyn/Documents/Zotero/storage/JYH8HFPH/S2468042723000799.html}
}

@article{yangBayesianDataAssimilation2022,
  title = {Bayesian Data Assimilation for Estimating Instantaneous Reproduction Numbers during Epidemics: {{Applications}} to {{COVID-19}}},
  shorttitle = {Bayesian Data Assimilation for Estimating Instantaneous Reproduction Numbers during Epidemics},
  author = {Yang, Xian and Wang, Shuo and Xing, Yuting and Li, Ling and Xu, Richard Yi Da and Friston, Karl J. and Guo, Yike},
  year = {2022},
  month = feb,
  journal = {PLOS Computational Biology},
  volume = {18},
  number = {2},
  pages = {e1009807},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1009807},
  urldate = {2024-12-23},
  abstract = {Estimating the changes of epidemiological parameters, such as instantaneous reproduction number, Rt, is important for understanding the transmission dynamics of infectious diseases. Current estimates of time-varying epidemiological parameters often face problems such as lagging observations, averaging inference, and improper quantification of uncertainties. To address these problems, we propose a Bayesian data assimilation framework for time-varying parameter estimation. Specifically, this framework is applied to estimate the instantaneous reproduction number Rt during emerging epidemics, resulting in the state-of-the-art `DARt' system. With DARt, time misalignment caused by lagging observations is tackled by incorporating observation delays into the joint inference of infections and Rt; the drawback of averaging is overcome by instantaneously updating upon new observations and developing a model selection mechanism that captures abrupt changes; the uncertainty is quantified and reduced by employing Bayesian smoothing. We validate the performance of DARt and demonstrate its power in describing the transmission dynamics of COVID-19. The proposed approach provides a promising solution for making accurate and timely estimation for transmission dynamics based on reported data.},
  langid = {english},
  keywords = {COVID 19,Distribution curves,Epidemiology,Infectious disease epidemiology,Infectious disease modeling,Random walk,Sweden,Vaccination and immunization},
  file = {/Users/nicsteyn/Documents/Zotero/storage/GNE22W4R/Yang et al. - 2022 - Bayesian data assimilation for estimating instanta.pdf}
}

@article{yangComparisonFilteringMethods2014,
  title = {Comparison of {{Filtering Methods}} for the {{Modeling}} and {{Retrospective Forecasting}} of {{Influenza Epidemics}}},
  author = {Yang, Wan and Karspeck, Alicia and Shaman, Jeffrey},
  year = {2014},
  month = apr,
  journal = {PLOS Computational Biology},
  volume = {10},
  number = {4},
  pages = {e1003583},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1003583},
  urldate = {2024-10-03},
  abstract = {A variety of filtering methods enable the recursive estimation of system state variables and inference of model parameters. These methods have found application in a range of disciplines and settings, including engineering design and forecasting, and, over the last two decades, have been applied to infectious disease epidemiology. For any system of interest, the ideal filter depends on the nonlinearity and complexity of the model to which it is applied, the quality and abundance of observations being entrained, and the ultimate application (e.g. forecast, parameter estimation, etc.). Here, we compare the performance of six state-of-the-art filter methods when used to model and forecast influenza activity. Three particle filters---a basic particle filter (PF) with resampling and regularization, maximum likelihood estimation via iterated filtering (MIF), and particle Markov chain Monte Carlo (pMCMC)---and three ensemble filters---the ensemble Kalman filter (EnKF), the ensemble adjustment Kalman filter (EAKF), and the rank histogram filter (RHF)---were used in conjunction with a humidity-forced susceptible-infectious-recovered-susceptible (SIRS) model and weekly estimates of influenza incidence. The modeling frameworks, first validated with synthetic influenza epidemic data, were then applied to fit and retrospectively forecast the historical incidence time series of seven influenza epidemics during 2003--2012, for 115 cities in the United States. Results suggest that when using the SIRS model the ensemble filters and the basic PF are more capable of faithfully recreating historical influenza incidence time series, while the MIF and pMCMC do not perform as well for multimodal outbreaks. For forecast of the week with the highest influenza activity, the accuracies of the six model-filter frameworks are comparable; the three particle filters perform slightly better predicting peaks 1--5 weeks in the future; the ensemble filters are more accurate predicting peaks in the past.},
  langid = {english},
  keywords = {Cities,Epidemiology,Forecasting,Influenza,Influenza A virus,Kalman filter,Nonlinear systems,Simulation and modeling},
  file = {/Users/nicsteyn/Documents/Zotero/storage/E8KP9JIC/Yang et al. - 2014 - Comparison of Filtering Methods for the Modeling a.pdf}
}
